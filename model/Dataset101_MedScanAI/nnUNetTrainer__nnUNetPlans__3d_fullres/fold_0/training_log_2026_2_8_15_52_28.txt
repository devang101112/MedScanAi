
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2026-02-08 15:52:28.856759: Using torch.compile... 
2026-02-08 15:52:29.466107: do_dummy_2d_data_aug: False 
2026-02-08 15:52:29.467096: Using splits from existing split file: /Data2/cse_23103045/nnUNet_preprocessed/Dataset101_MedScanAI/splits_final.json 
2026-02-08 15:52:29.467311: The split file contains 5 splits. 
2026-02-08 15:52:29.467342: Desired fold for training: 0 
2026-02-08 15:52:29.467363: This split has 378 training and 95 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [417.0, 512.0, 512.0], 'spacing': [1.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset101_MedScanAI', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [103, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 103.05046844482422, 'median': 102.0, 'min': -1022.0, 'percentile_00_5': -57.0, 'percentile_99_5': 302.0, 'std': 73.22535705566406}}} 
 
2026-02-08 15:52:29.928241: Unable to plot network architecture: nnUNet_compile is enabled! 
2026-02-08 15:52:29.938473:  
2026-02-08 15:52:29.938681: Epoch 0 
2026-02-08 15:52:29.938945: Current learning rate: 0.01 
2026-02-08 15:53:24.322890: train_loss -0.0754 
2026-02-08 15:53:24.323197: val_loss -0.2652 
2026-02-08 15:53:24.323361: Pseudo dice [np.float32(0.5725)] 
2026-02-08 15:53:24.323673: Epoch time: 54.39 s 
2026-02-08 15:53:24.323757: Yayy! New best EMA pseudo Dice: 0.5724999904632568 
2026-02-08 15:53:25.129956:  
2026-02-08 15:53:25.130086: Epoch 1 
2026-02-08 15:53:25.130259: Current learning rate: 0.00999 
2026-02-08 15:53:49.851484: train_loss -0.272 
2026-02-08 15:53:49.851871: val_loss -0.2649 
2026-02-08 15:53:49.851952: Pseudo dice [np.float32(0.5468)] 
2026-02-08 15:53:49.852025: Epoch time: 24.72 s 
2026-02-08 15:53:50.512165:  
2026-02-08 15:53:50.512360: Epoch 2 
2026-02-08 15:53:50.512462: Current learning rate: 0.00998 
2026-02-08 15:54:15.457094: train_loss -0.4098 
2026-02-08 15:54:15.457499: val_loss -0.3437 
2026-02-08 15:54:15.457548: Pseudo dice [np.float32(0.6213)] 
2026-02-08 15:54:15.457603: Epoch time: 24.95 s 
2026-02-08 15:54:15.457646: Yayy! New best EMA pseudo Dice: 0.5751000046730042 
2026-02-08 15:54:16.556719:  
2026-02-08 15:54:16.556944: Epoch 3 
2026-02-08 15:54:16.557042: Current learning rate: 0.00997 
2026-02-08 15:54:41.391967: train_loss -0.42 
2026-02-08 15:54:41.392275: val_loss -0.4699 
2026-02-08 15:54:41.392360: Pseudo dice [np.float32(0.714)] 
2026-02-08 15:54:41.392419: Epoch time: 24.84 s 
2026-02-08 15:54:41.392529: Yayy! New best EMA pseudo Dice: 0.5889999866485596 
2026-02-08 15:54:42.441283:  
2026-02-08 15:54:42.441452: Epoch 4 
2026-02-08 15:54:42.441549: Current learning rate: 0.00996 
2026-02-08 15:55:07.340078: train_loss -0.5415 
2026-02-08 15:55:07.340599: val_loss -0.4086 
2026-02-08 15:55:07.340648: Pseudo dice [np.float32(0.6516)] 
2026-02-08 15:55:07.340702: Epoch time: 24.9 s 
2026-02-08 15:55:07.340738: Yayy! New best EMA pseudo Dice: 0.595300018787384 
2026-02-08 15:55:08.377498:  
2026-02-08 15:55:08.377686: Epoch 5 
2026-02-08 15:55:08.377788: Current learning rate: 0.00995 
2026-02-08 15:55:33.186943: train_loss -0.5955 
2026-02-08 15:55:33.187291: val_loss -0.5874 
2026-02-08 15:55:33.187424: Pseudo dice [np.float32(0.7763)] 
2026-02-08 15:55:33.187528: Epoch time: 24.81 s 
2026-02-08 15:55:33.187614: Yayy! New best EMA pseudo Dice: 0.6133999824523926 
2026-02-08 15:55:34.202082:  
2026-02-08 15:55:34.202249: Epoch 6 
2026-02-08 15:55:34.202354: Current learning rate: 0.00995 
2026-02-08 15:55:59.097502: train_loss -0.6254 
2026-02-08 15:55:59.097967: val_loss -0.6281 
2026-02-08 15:55:59.098012: Pseudo dice [np.float32(0.7948)] 
2026-02-08 15:55:59.098067: Epoch time: 24.9 s 
2026-02-08 15:55:59.098104: Yayy! New best EMA pseudo Dice: 0.6315000057220459 
2026-02-08 15:56:00.114241:  
2026-02-08 15:56:00.114527: Epoch 7 
2026-02-08 15:56:00.114691: Current learning rate: 0.00994 
2026-02-08 15:56:24.978229: train_loss -0.5681 
2026-02-08 15:56:24.978660: val_loss -0.6487 
2026-02-08 15:56:24.978704: Pseudo dice [np.float32(0.8095)] 
2026-02-08 15:56:24.978760: Epoch time: 24.86 s 
2026-02-08 15:56:24.978796: Yayy! New best EMA pseudo Dice: 0.6492999792098999 
2026-02-08 15:56:26.011412:  
2026-02-08 15:56:26.011573: Epoch 8 
2026-02-08 15:56:26.011699: Current learning rate: 0.00993 
2026-02-08 15:56:50.905903: train_loss -0.6657 
2026-02-08 15:56:50.906289: val_loss -0.6603 
2026-02-08 15:56:50.906334: Pseudo dice [np.float32(0.8348)] 
2026-02-08 15:56:50.906388: Epoch time: 24.9 s 
2026-02-08 15:56:50.906424: Yayy! New best EMA pseudo Dice: 0.6678000092506409 
2026-02-08 15:56:52.045200:  
2026-02-08 15:56:52.045360: Epoch 9 
2026-02-08 15:56:52.045462: Current learning rate: 0.00992 
2026-02-08 15:57:16.916203: train_loss -0.6298 
2026-02-08 15:57:16.916658: val_loss -0.6952 
2026-02-08 15:57:16.916703: Pseudo dice [np.float32(0.8462)] 
2026-02-08 15:57:16.916757: Epoch time: 24.87 s 
2026-02-08 15:57:16.916793: Yayy! New best EMA pseudo Dice: 0.685699999332428 
2026-02-08 15:57:18.018528:  
2026-02-08 15:57:18.018854: Epoch 10 
2026-02-08 15:57:18.018955: Current learning rate: 0.00991 
2026-02-08 15:57:42.835861: train_loss -0.6907 
2026-02-08 15:57:42.836250: val_loss -0.718 
2026-02-08 15:57:42.836306: Pseudo dice [np.float32(0.8482)] 
2026-02-08 15:57:42.836362: Epoch time: 24.82 s 
2026-02-08 15:57:42.836397: Yayy! New best EMA pseudo Dice: 0.7019000053405762 
2026-02-08 15:57:44.301264:  
2026-02-08 15:57:44.301419: Epoch 11 
2026-02-08 15:57:44.301514: Current learning rate: 0.0099 
2026-02-08 15:58:10.671776: train_loss -0.6591 
2026-02-08 15:58:10.672032: val_loss -0.7711 
2026-02-08 15:58:10.672081: Pseudo dice [np.float32(0.8866)] 
2026-02-08 15:58:10.672135: Epoch time: 26.37 s 
2026-02-08 15:58:10.672170: Yayy! New best EMA pseudo Dice: 0.7203999757766724 
2026-02-08 15:58:11.724931:  
2026-02-08 15:58:11.725103: Epoch 12 
2026-02-08 15:58:11.725199: Current learning rate: 0.00989 
2026-02-08 15:59:00.139100: train_loss -0.7034 
2026-02-08 15:59:00.139512: val_loss -0.7389 
2026-02-08 15:59:00.139558: Pseudo dice [np.float32(0.8541)] 
2026-02-08 15:59:00.139610: Epoch time: 48.41 s 
2026-02-08 15:59:00.139645: Yayy! New best EMA pseudo Dice: 0.7337999939918518 
2026-02-08 15:59:01.208095:  
2026-02-08 15:59:01.208442: Epoch 13 
2026-02-08 15:59:01.208542: Current learning rate: 0.00988 
2026-02-08 15:59:43.659426: train_loss -0.6761 
2026-02-08 15:59:43.659847: val_loss -0.6672 
2026-02-08 15:59:43.659892: Pseudo dice [np.float32(0.8141)] 
2026-02-08 15:59:43.659946: Epoch time: 42.45 s 
2026-02-08 15:59:43.659980: Yayy! New best EMA pseudo Dice: 0.7418000102043152 
2026-02-08 15:59:44.749199:  
2026-02-08 15:59:44.749521: Epoch 14 
2026-02-08 15:59:44.749618: Current learning rate: 0.00987 
2026-02-08 16:00:34.647098: train_loss -0.6764 
2026-02-08 16:00:34.647509: val_loss -0.7723 
2026-02-08 16:00:34.647711: Pseudo dice [np.float32(0.8828)] 
2026-02-08 16:00:34.647770: Epoch time: 49.9 s 
2026-02-08 16:00:34.647806: Yayy! New best EMA pseudo Dice: 0.7559000253677368 
2026-02-08 16:00:35.729279:  
2026-02-08 16:00:35.729579: Epoch 15 
2026-02-08 16:00:35.729707: Current learning rate: 0.00986 
2026-02-08 16:01:25.608189: train_loss -0.7428 
2026-02-08 16:01:25.608630: val_loss -0.8256 
2026-02-08 16:01:25.608676: Pseudo dice [np.float32(0.9103)] 
2026-02-08 16:01:25.608730: Epoch time: 49.88 s 
2026-02-08 16:01:25.608767: Yayy! New best EMA pseudo Dice: 0.7713000178337097 
2026-02-08 16:01:26.697154:  
2026-02-08 16:01:26.697344: Epoch 16 
2026-02-08 16:01:26.697441: Current learning rate: 0.00986 
2026-02-08 16:02:16.638458: train_loss -0.7351 
2026-02-08 16:02:16.638880: val_loss -0.7565 
2026-02-08 16:02:16.638953: Pseudo dice [np.float32(0.8704)] 
2026-02-08 16:02:16.639009: Epoch time: 49.94 s 
2026-02-08 16:02:16.639046: Yayy! New best EMA pseudo Dice: 0.7811999917030334 
2026-02-08 16:02:17.757129:  
2026-02-08 16:02:17.757261: Epoch 17 
2026-02-08 16:02:17.757365: Current learning rate: 0.00985 
2026-02-08 16:03:07.732467: train_loss -0.685 
2026-02-08 16:03:07.732857: val_loss -0.7337 
2026-02-08 16:03:07.732903: Pseudo dice [np.float32(0.8545)] 
2026-02-08 16:03:07.732957: Epoch time: 49.98 s 
2026-02-08 16:03:07.732993: Yayy! New best EMA pseudo Dice: 0.7886000275611877 
2026-02-08 16:03:08.908702:  
2026-02-08 16:03:08.908837: Epoch 18 
2026-02-08 16:03:08.908935: Current learning rate: 0.00984 
2026-02-08 16:03:59.012411: train_loss -0.7467 
2026-02-08 16:03:59.012793: val_loss -0.7681 
2026-02-08 16:03:59.012836: Pseudo dice [np.float32(0.8542)] 
2026-02-08 16:03:59.012887: Epoch time: 50.1 s 
2026-02-08 16:03:59.012922: Yayy! New best EMA pseudo Dice: 0.7950999736785889 
2026-02-08 16:04:00.133582:  
2026-02-08 16:04:00.133911: Epoch 19 
2026-02-08 16:04:00.134038: Current learning rate: 0.00983 
2026-02-08 16:04:50.257772: train_loss -0.7607 
2026-02-08 16:04:50.258157: val_loss -0.711 
2026-02-08 16:04:50.258296: Pseudo dice [np.float32(0.8445)] 
2026-02-08 16:04:50.258389: Epoch time: 50.12 s 
2026-02-08 16:04:50.258436: Yayy! New best EMA pseudo Dice: 0.8001000285148621 
2026-02-08 16:04:51.403051:  
2026-02-08 16:04:51.403202: Epoch 20 
2026-02-08 16:04:51.403310: Current learning rate: 0.00982 
2026-02-08 16:05:52.729201: train_loss -0.7707 
2026-02-08 16:05:52.729589: val_loss -0.6354 
2026-02-08 16:05:52.729635: Pseudo dice [np.float32(0.7982)] 
2026-02-08 16:05:52.729692: Epoch time: 61.33 s 
2026-02-08 16:05:53.431691:  
2026-02-08 16:05:53.431954: Epoch 21 
2026-02-08 16:05:53.432111: Current learning rate: 0.00981 
2026-02-08 16:07:01.033423: train_loss -0.7422 
2026-02-08 16:07:01.033879: val_loss -0.6988 
2026-02-08 16:07:01.033921: Pseudo dice [np.float32(0.8413)] 
2026-02-08 16:07:01.033972: Epoch time: 67.6 s 
2026-02-08 16:07:01.034008: Yayy! New best EMA pseudo Dice: 0.8040000200271606 
2026-02-08 16:07:02.167633:  
2026-02-08 16:07:02.167905: Epoch 22 
2026-02-08 16:07:02.168045: Current learning rate: 0.0098 
2026-02-08 16:08:13.242560: train_loss -0.7585 
2026-02-08 16:08:13.242991: val_loss -0.8061 
2026-02-08 16:08:13.243039: Pseudo dice [np.float32(0.8838)] 
2026-02-08 16:08:13.243093: Epoch time: 71.08 s 
2026-02-08 16:08:13.243129: Yayy! New best EMA pseudo Dice: 0.8119999766349792 
2026-02-08 16:08:14.352391:  
2026-02-08 16:08:14.352723: Epoch 23 
2026-02-08 16:08:14.352843: Current learning rate: 0.00979 
2026-02-08 16:09:24.008055: train_loss -0.7806 
2026-02-08 16:09:24.008462: val_loss -0.834 
2026-02-08 16:09:24.008506: Pseudo dice [np.float32(0.9097)] 
2026-02-08 16:09:24.008555: Epoch time: 69.66 s 
2026-02-08 16:09:24.008592: Yayy! New best EMA pseudo Dice: 0.8217999935150146 
2026-02-08 16:09:25.644574:  
2026-02-08 16:09:25.644850: Epoch 24 
2026-02-08 16:09:25.644977: Current learning rate: 0.00978 
2026-02-08 16:10:34.171186: train_loss -0.7731 
2026-02-08 16:10:34.171683: val_loss -0.7696 
2026-02-08 16:10:34.171731: Pseudo dice [np.float32(0.8818)] 
2026-02-08 16:10:34.171787: Epoch time: 68.53 s 
2026-02-08 16:10:34.171826: Yayy! New best EMA pseudo Dice: 0.8277999758720398 
2026-02-08 16:10:35.291318:  
2026-02-08 16:10:35.291699: Epoch 25 
2026-02-08 16:10:35.291797: Current learning rate: 0.00977 
2026-02-08 16:11:44.542902: train_loss -0.7805 
2026-02-08 16:11:44.543313: val_loss -0.6994 
2026-02-08 16:11:44.543360: Pseudo dice [np.float32(0.8237)] 
2026-02-08 16:11:44.543421: Epoch time: 69.25 s 
2026-02-08 16:11:45.218246:  
2026-02-08 16:11:45.218435: Epoch 26 
2026-02-08 16:11:45.218590: Current learning rate: 0.00977 
2026-02-08 16:12:54.804400: train_loss -0.7847 
2026-02-08 16:12:54.811807: val_loss -0.7967 
2026-02-08 16:12:54.811964: Pseudo dice [np.float32(0.8802)] 
2026-02-08 16:12:54.812021: Epoch time: 69.59 s 
2026-02-08 16:12:54.812057: Yayy! New best EMA pseudo Dice: 0.8327000141143799 
2026-02-08 16:12:55.898090:  
2026-02-08 16:12:55.898344: Epoch 27 
2026-02-08 16:12:55.898443: Current learning rate: 0.00976 
2026-02-08 16:14:03.822594: train_loss -0.7755 
2026-02-08 16:14:03.823000: val_loss -0.7889 
2026-02-08 16:14:03.823042: Pseudo dice [np.float32(0.8796)] 
2026-02-08 16:14:03.823090: Epoch time: 67.93 s 
2026-02-08 16:14:03.823125: Yayy! New best EMA pseudo Dice: 0.8373000025749207 
2026-02-08 16:14:04.927579:  
2026-02-08 16:14:04.927707: Epoch 28 
2026-02-08 16:14:04.927804: Current learning rate: 0.00975 
2026-02-08 16:15:15.467374: train_loss -0.7984 
2026-02-08 16:15:15.467723: val_loss -0.7972 
2026-02-08 16:15:15.467767: Pseudo dice [np.float32(0.8953)] 
2026-02-08 16:15:15.467817: Epoch time: 70.54 s 
2026-02-08 16:15:15.467851: Yayy! New best EMA pseudo Dice: 0.8431000113487244 
2026-02-08 16:15:16.570157:  
2026-02-08 16:15:16.570343: Epoch 29 
2026-02-08 16:15:16.570484: Current learning rate: 0.00974 
2026-02-08 16:16:24.257293: train_loss -0.7646 
2026-02-08 16:16:24.257656: val_loss -0.5202 
2026-02-08 16:16:24.257699: Pseudo dice [np.float32(0.7713)] 
2026-02-08 16:16:24.257748: Epoch time: 67.69 s 
2026-02-08 16:16:24.949392:  
2026-02-08 16:16:24.949578: Epoch 30 
2026-02-08 16:16:24.949672: Current learning rate: 0.00973 
2026-02-08 16:17:33.999737: train_loss -0.7386 
2026-02-08 16:17:34.000020: val_loss -0.7281 
2026-02-08 16:17:34.000081: Pseudo dice [np.float32(0.86)] 
2026-02-08 16:17:34.000211: Epoch time: 69.05 s 
2026-02-08 16:17:34.681130:  
2026-02-08 16:17:34.681259: Epoch 31 
2026-02-08 16:17:34.681366: Current learning rate: 0.00972 
2026-02-08 16:18:45.014667: train_loss -0.8088 
2026-02-08 16:18:45.015092: val_loss -0.789 
2026-02-08 16:18:45.015136: Pseudo dice [np.float32(0.8838)] 
2026-02-08 16:18:45.015189: Epoch time: 70.33 s 
2026-02-08 16:18:45.703330:  
2026-02-08 16:18:45.703564: Epoch 32 
2026-02-08 16:18:45.703666: Current learning rate: 0.00971 
2026-02-08 16:19:52.748491: train_loss -0.7963 
2026-02-08 16:19:52.748897: val_loss -0.7927 
2026-02-08 16:19:52.748940: Pseudo dice [np.float32(0.8989)] 
2026-02-08 16:19:52.748996: Epoch time: 67.05 s 
2026-02-08 16:19:52.749032: Yayy! New best EMA pseudo Dice: 0.8485000133514404 
2026-02-08 16:19:53.804176:  
2026-02-08 16:19:53.804407: Epoch 33 
2026-02-08 16:19:53.804543: Current learning rate: 0.0097 
2026-02-08 16:21:01.860834: train_loss -0.8011 
2026-02-08 16:21:01.861234: val_loss -0.7531 
2026-02-08 16:21:01.861289: Pseudo dice [np.float32(0.8757)] 
2026-02-08 16:21:01.861342: Epoch time: 68.06 s 
2026-02-08 16:21:01.861377: Yayy! New best EMA pseudo Dice: 0.8511999845504761 
2026-02-08 16:21:02.972581:  
2026-02-08 16:21:02.972758: Epoch 34 
2026-02-08 16:21:02.972855: Current learning rate: 0.00969 
2026-02-08 16:22:12.016038: train_loss -0.8401 
2026-02-08 16:22:12.016474: val_loss -0.8122 
2026-02-08 16:22:12.016521: Pseudo dice [np.float32(0.8948)] 
2026-02-08 16:22:12.016572: Epoch time: 69.04 s 
2026-02-08 16:22:12.016608: Yayy! New best EMA pseudo Dice: 0.8555999994277954 
2026-02-08 16:22:13.117548:  
2026-02-08 16:22:13.117763: Epoch 35 
2026-02-08 16:22:13.117886: Current learning rate: 0.00968 
2026-02-08 16:23:23.381289: train_loss -0.8337 
2026-02-08 16:23:23.381735: val_loss -0.8762 
2026-02-08 16:23:23.381776: Pseudo dice [np.float32(0.9362)] 
2026-02-08 16:23:23.381914: Epoch time: 70.26 s 
2026-02-08 16:23:23.381954: Yayy! New best EMA pseudo Dice: 0.8636000156402588 
2026-02-08 16:23:24.505992:  
2026-02-08 16:23:24.506248: Epoch 36 
2026-02-08 16:23:24.506391: Current learning rate: 0.00968 
2026-02-08 16:24:31.086677: train_loss -0.8032 
2026-02-08 16:24:31.087026: val_loss -0.8058 
2026-02-08 16:24:31.087101: Pseudo dice [np.float32(0.8933)] 
2026-02-08 16:24:31.087157: Epoch time: 66.58 s 
2026-02-08 16:24:31.087195: Yayy! New best EMA pseudo Dice: 0.866599977016449 
2026-02-08 16:24:32.752325:  
2026-02-08 16:24:32.752561: Epoch 37 
2026-02-08 16:24:32.752672: Current learning rate: 0.00967 
2026-02-08 16:25:42.820031: train_loss -0.8142 
2026-02-08 16:25:42.820389: val_loss -0.8289 
2026-02-08 16:25:42.820478: Pseudo dice [np.float32(0.9115)] 
2026-02-08 16:25:42.820549: Epoch time: 70.07 s 
2026-02-08 16:25:42.820609: Yayy! New best EMA pseudo Dice: 0.8711000084877014 
2026-02-08 16:25:43.894181:  
2026-02-08 16:25:43.894431: Epoch 38 
2026-02-08 16:25:43.894535: Current learning rate: 0.00966 
2026-02-08 16:26:52.528514: train_loss -0.8019 
2026-02-08 16:26:52.528873: val_loss -0.6928 
2026-02-08 16:26:52.528923: Pseudo dice [np.float32(0.8526)] 
2026-02-08 16:26:52.528981: Epoch time: 68.64 s 
2026-02-08 16:26:53.240164:  
2026-02-08 16:26:53.240452: Epoch 39 
2026-02-08 16:26:53.240553: Current learning rate: 0.00965 
2026-02-08 16:28:01.798315: train_loss -0.797 
2026-02-08 16:28:01.798784: val_loss -0.7882 
2026-02-08 16:28:01.798836: Pseudo dice [np.float32(0.9086)] 
2026-02-08 16:28:01.798892: Epoch time: 68.56 s 
2026-02-08 16:28:01.798929: Yayy! New best EMA pseudo Dice: 0.873199999332428 
2026-02-08 16:28:02.942472:  
2026-02-08 16:28:02.942847: Epoch 40 
2026-02-08 16:28:02.942947: Current learning rate: 0.00964 
2026-02-08 16:29:10.130128: train_loss -0.8127 
2026-02-08 16:29:10.130598: val_loss -0.8446 
2026-02-08 16:29:10.130648: Pseudo dice [np.float32(0.9184)] 
2026-02-08 16:29:10.130704: Epoch time: 67.19 s 
2026-02-08 16:29:10.130740: Yayy! New best EMA pseudo Dice: 0.8776999711990356 
2026-02-08 16:29:11.249999:  
2026-02-08 16:29:11.250229: Epoch 41 
2026-02-08 16:29:11.250382: Current learning rate: 0.00963 
2026-02-08 16:30:24.389410: train_loss -0.8304 
2026-02-08 16:30:24.389788: val_loss -0.8303 
2026-02-08 16:30:24.389832: Pseudo dice [np.float32(0.918)] 
2026-02-08 16:30:24.389888: Epoch time: 73.14 s 
2026-02-08 16:30:24.389923: Yayy! New best EMA pseudo Dice: 0.8816999793052673 
2026-02-08 16:30:25.522460:  
2026-02-08 16:30:25.522658: Epoch 42 
2026-02-08 16:30:25.522760: Current learning rate: 0.00962 
2026-02-08 16:31:36.039313: train_loss -0.8092 
2026-02-08 16:31:36.039762: val_loss -0.8973 
2026-02-08 16:31:36.039806: Pseudo dice [np.float32(0.9517)] 
2026-02-08 16:31:36.039864: Epoch time: 70.52 s 
2026-02-08 16:31:36.039899: Yayy! New best EMA pseudo Dice: 0.888700008392334 
2026-02-08 16:31:37.137506:  
2026-02-08 16:31:37.137745: Epoch 43 
2026-02-08 16:31:37.137849: Current learning rate: 0.00961 
2026-02-08 16:32:47.387643: train_loss -0.8322 
2026-02-08 16:32:47.388121: val_loss -0.8576 
2026-02-08 16:32:47.388167: Pseudo dice [np.float32(0.9264)] 
2026-02-08 16:32:47.388223: Epoch time: 70.25 s 
2026-02-08 16:32:47.388259: Yayy! New best EMA pseudo Dice: 0.8924999833106995 
2026-02-08 16:32:48.497569:  
2026-02-08 16:32:48.497750: Epoch 44 
2026-02-08 16:32:48.497848: Current learning rate: 0.0096 
2026-02-08 16:33:55.944996: train_loss -0.8515 
2026-02-08 16:33:55.945495: val_loss -0.8592 
2026-02-08 16:33:55.945541: Pseudo dice [np.float32(0.9235)] 
2026-02-08 16:33:55.945597: Epoch time: 67.45 s 
2026-02-08 16:33:55.945632: Yayy! New best EMA pseudo Dice: 0.8956000208854675 
2026-02-08 16:33:57.068203:  
2026-02-08 16:33:57.068390: Epoch 45 
2026-02-08 16:33:57.068500: Current learning rate: 0.00959 
2026-02-08 16:35:06.296928: train_loss -0.8301 
2026-02-08 16:35:06.297410: val_loss -0.8094 
2026-02-08 16:35:06.297455: Pseudo dice [np.float32(0.8813)] 
2026-02-08 16:35:06.297510: Epoch time: 69.23 s 
2026-02-08 16:35:06.981806:  
2026-02-08 16:35:06.982042: Epoch 46 
2026-02-08 16:35:06.982197: Current learning rate: 0.00959 
2026-02-08 16:36:15.798548: train_loss -0.7584 
2026-02-08 16:36:15.798795: val_loss -0.8566 
2026-02-08 16:36:15.798846: Pseudo dice [np.float32(0.9346)] 
2026-02-08 16:36:15.798900: Epoch time: 68.82 s 
2026-02-08 16:36:15.798936: Yayy! New best EMA pseudo Dice: 0.8981999754905701 
2026-02-08 16:36:16.910512:  
2026-02-08 16:36:16.910728: Epoch 47 
2026-02-08 16:36:16.910826: Current learning rate: 0.00958 
2026-02-08 16:37:27.249425: train_loss -0.7967 
2026-02-08 16:37:27.249824: val_loss -0.8603 
2026-02-08 16:37:27.249866: Pseudo dice [np.float32(0.9252)] 
2026-02-08 16:37:27.249917: Epoch time: 70.34 s 
2026-02-08 16:37:27.249951: Yayy! New best EMA pseudo Dice: 0.9009000062942505 
2026-02-08 16:37:28.325466:  
2026-02-08 16:37:28.325781: Epoch 48 
2026-02-08 16:37:28.325879: Current learning rate: 0.00957 
2026-02-08 16:38:36.555193: train_loss -0.8205 
2026-02-08 16:38:36.555659: val_loss -0.7761 
2026-02-08 16:38:36.555705: Pseudo dice [np.float32(0.8731)] 
2026-02-08 16:38:36.555768: Epoch time: 68.23 s 
2026-02-08 16:38:37.240054:  
2026-02-08 16:38:37.240336: Epoch 49 
2026-02-08 16:38:37.240596: Current learning rate: 0.00956 
2026-02-08 16:39:46.521417: train_loss -0.8204 
2026-02-08 16:39:46.521855: val_loss -0.8486 
2026-02-08 16:39:46.521930: Pseudo dice [np.float32(0.9291)] 
2026-02-08 16:39:46.521998: Epoch time: 69.28 s 
2026-02-08 16:39:46.789601: Yayy! New best EMA pseudo Dice: 0.901199996471405 
2026-02-08 16:39:48.443688:  
2026-02-08 16:39:48.443895: Epoch 50 
2026-02-08 16:39:48.443998: Current learning rate: 0.00955 
2026-02-08 16:40:56.926357: train_loss -0.8429 
2026-02-08 16:40:56.926764: val_loss -0.8096 
2026-02-08 16:40:56.926808: Pseudo dice [np.float32(0.8953)] 
2026-02-08 16:40:56.926872: Epoch time: 68.48 s 
2026-02-08 16:40:57.618417:  
2026-02-08 16:40:57.618802: Epoch 51 
2026-02-08 16:40:57.618901: Current learning rate: 0.00954 
2026-02-08 16:42:04.240716: train_loss -0.8267 
2026-02-08 16:42:04.241189: val_loss -0.856 
2026-02-08 16:42:04.241235: Pseudo dice [np.float32(0.8999)] 
2026-02-08 16:42:04.241308: Epoch time: 66.62 s 
2026-02-08 16:42:04.933227:  
2026-02-08 16:42:04.933602: Epoch 52 
2026-02-08 16:42:04.933702: Current learning rate: 0.00953 
2026-02-08 16:43:12.553245: train_loss -0.8457 
2026-02-08 16:43:12.553724: val_loss -0.8437 
2026-02-08 16:43:12.553767: Pseudo dice [np.float32(0.9198)] 
2026-02-08 16:43:12.553827: Epoch time: 67.62 s 
2026-02-08 16:43:12.553862: Yayy! New best EMA pseudo Dice: 0.9024999737739563 
2026-02-08 16:43:13.702173:  
2026-02-08 16:43:13.702379: Epoch 53 
2026-02-08 16:43:13.702481: Current learning rate: 0.00952 
2026-02-08 16:44:22.328820: train_loss -0.8562 
2026-02-08 16:44:22.329233: val_loss -0.8749 
2026-02-08 16:44:22.329286: Pseudo dice [np.float32(0.9395)] 
2026-02-08 16:44:22.329345: Epoch time: 68.63 s 
2026-02-08 16:44:22.329381: Yayy! New best EMA pseudo Dice: 0.9061999917030334 
2026-02-08 16:44:23.463295:  
2026-02-08 16:44:23.463623: Epoch 54 
2026-02-08 16:44:23.463745: Current learning rate: 0.00951 
2026-02-08 16:45:30.030478: train_loss -0.8765 
2026-02-08 16:45:30.030901: val_loss -0.8037 
2026-02-08 16:45:30.030946: Pseudo dice [np.float32(0.8765)] 
2026-02-08 16:45:30.031003: Epoch time: 66.57 s 
2026-02-08 16:45:30.713824:  
2026-02-08 16:45:30.714050: Epoch 55 
2026-02-08 16:45:30.714149: Current learning rate: 0.0095 
2026-02-08 16:46:38.012654: train_loss -0.8707 
2026-02-08 16:46:38.013039: val_loss -0.8356 
2026-02-08 16:46:38.013088: Pseudo dice [np.float32(0.9118)] 
2026-02-08 16:46:38.013144: Epoch time: 67.3 s 
2026-02-08 16:46:38.704157:  
2026-02-08 16:46:38.704535: Epoch 56 
2026-02-08 16:46:38.704635: Current learning rate: 0.00949 
2026-02-08 16:47:44.229415: train_loss -0.8792 
2026-02-08 16:47:44.229790: val_loss -0.8359 
2026-02-08 16:47:44.229867: Pseudo dice [np.float32(0.9187)] 
2026-02-08 16:47:44.229954: Epoch time: 65.53 s 
2026-02-08 16:47:44.910330:  
2026-02-08 16:47:44.910558: Epoch 57 
2026-02-08 16:47:44.910660: Current learning rate: 0.00949 
2026-02-08 16:48:51.024102: train_loss -0.8182 
2026-02-08 16:48:51.024500: val_loss -0.8714 
2026-02-08 16:48:51.024831: Pseudo dice [np.float32(0.9348)] 
2026-02-08 16:48:51.024900: Epoch time: 66.11 s 
2026-02-08 16:48:51.024940: Yayy! New best EMA pseudo Dice: 0.9085000157356262 
2026-02-08 16:48:52.103880:  
2026-02-08 16:48:52.104056: Epoch 58 
2026-02-08 16:48:52.104208: Current learning rate: 0.00948 
2026-02-08 16:50:02.664350: train_loss -0.8093 
2026-02-08 16:50:02.664846: val_loss -0.8577 
2026-02-08 16:50:02.664894: Pseudo dice [np.float32(0.9281)] 
2026-02-08 16:50:02.664956: Epoch time: 70.56 s 
2026-02-08 16:50:02.664991: Yayy! New best EMA pseudo Dice: 0.9103999733924866 
2026-02-08 16:50:03.753455:  
2026-02-08 16:50:03.753661: Epoch 59 
2026-02-08 16:50:03.753799: Current learning rate: 0.00947 
2026-02-08 16:51:12.555885: train_loss -0.8185 
2026-02-08 16:51:12.556328: val_loss -0.8702 
2026-02-08 16:51:12.556381: Pseudo dice [np.float32(0.9359)] 
2026-02-08 16:51:12.556447: Epoch time: 68.8 s 
2026-02-08 16:51:12.556482: Yayy! New best EMA pseudo Dice: 0.9129999876022339 
2026-02-08 16:51:13.655301:  
2026-02-08 16:51:13.655416: Epoch 60 
2026-02-08 16:51:13.655511: Current learning rate: 0.00946 
2026-02-08 16:52:20.457674: train_loss -0.8439 
2026-02-08 16:52:20.458125: val_loss -0.8737 
2026-02-08 16:52:20.458172: Pseudo dice [np.float32(0.9373)] 
2026-02-08 16:52:20.458229: Epoch time: 66.8 s 
2026-02-08 16:52:20.458264: Yayy! New best EMA pseudo Dice: 0.9154000282287598 
2026-02-08 16:52:21.524541:  
2026-02-08 16:52:21.524819: Epoch 61 
2026-02-08 16:52:21.524918: Current learning rate: 0.00945 
2026-02-08 16:53:30.358844: train_loss -0.758 
2026-02-08 16:53:30.359241: val_loss -0.8136 
2026-02-08 16:53:30.359300: Pseudo dice [np.float32(0.9071)] 
2026-02-08 16:53:30.359358: Epoch time: 68.84 s 
2026-02-08 16:53:31.042207:  
2026-02-08 16:53:31.042346: Epoch 62 
2026-02-08 16:53:31.042449: Current learning rate: 0.00944 
2026-02-08 16:54:39.934468: train_loss -0.7935 
2026-02-08 16:54:39.934887: val_loss -0.8289 
2026-02-08 16:54:39.934934: Pseudo dice [np.float32(0.8981)] 
2026-02-08 16:54:39.934992: Epoch time: 68.89 s 
2026-02-08 16:54:40.616498:  
2026-02-08 16:54:40.616666: Epoch 63 
2026-02-08 16:54:40.616767: Current learning rate: 0.00943 
2026-02-08 16:55:46.537166: train_loss -0.8282 
2026-02-08 16:55:46.537562: val_loss -0.815 
2026-02-08 16:55:46.537635: Pseudo dice [np.float32(0.8998)] 
2026-02-08 16:55:46.537694: Epoch time: 65.92 s 
2026-02-08 16:55:47.789141:  
2026-02-08 16:55:47.789387: Epoch 64 
2026-02-08 16:55:47.789493: Current learning rate: 0.00942 
2026-02-08 16:56:54.683568: train_loss -0.8098 
2026-02-08 16:56:54.684017: val_loss -0.858 
2026-02-08 16:56:54.684059: Pseudo dice [np.float32(0.9175)] 
2026-02-08 16:56:54.684118: Epoch time: 66.9 s 
2026-02-08 16:56:55.368974:  
2026-02-08 16:56:55.369223: Epoch 65 
2026-02-08 16:56:55.369338: Current learning rate: 0.00941 
2026-02-08 16:58:05.270075: train_loss -0.8102 
2026-02-08 16:58:05.270497: val_loss -0.7219 
2026-02-08 16:58:05.270548: Pseudo dice [np.float32(0.8242)] 
2026-02-08 16:58:05.270604: Epoch time: 69.9 s 
2026-02-08 16:58:05.957622:  
2026-02-08 16:58:05.957919: Epoch 66 
2026-02-08 16:58:05.958057: Current learning rate: 0.0094 
2026-02-08 16:59:12.307978: train_loss -0.7934 
2026-02-08 16:59:12.308381: val_loss -0.8067 
2026-02-08 16:59:12.308428: Pseudo dice [np.float32(0.8922)] 
2026-02-08 16:59:12.308484: Epoch time: 66.35 s 
2026-02-08 16:59:12.996883:  
2026-02-08 16:59:12.997106: Epoch 67 
2026-02-08 16:59:12.997201: Current learning rate: 0.00939 
2026-02-08 17:00:18.681717: train_loss -0.7823 
2026-02-08 17:00:18.682147: val_loss -0.8515 
2026-02-08 17:00:18.682195: Pseudo dice [np.float32(0.9263)] 
2026-02-08 17:00:18.682255: Epoch time: 65.69 s 
2026-02-08 17:00:19.375610:  
2026-02-08 17:00:19.375854: Epoch 68 
2026-02-08 17:00:19.375951: Current learning rate: 0.00939 
2026-02-08 17:01:26.931094: train_loss -0.8022 
2026-02-08 17:01:26.931547: val_loss -0.8864 
2026-02-08 17:01:26.931592: Pseudo dice [np.float32(0.9438)] 
2026-02-08 17:01:26.931651: Epoch time: 67.56 s 
2026-02-08 17:01:27.623273:  
2026-02-08 17:01:27.623535: Epoch 69 
2026-02-08 17:01:27.623637: Current learning rate: 0.00938 
2026-02-08 17:02:36.277792: train_loss -0.846 
2026-02-08 17:02:36.278282: val_loss -0.8668 
2026-02-08 17:02:36.278330: Pseudo dice [np.float32(0.9274)] 
2026-02-08 17:02:36.278387: Epoch time: 68.66 s 
2026-02-08 17:02:36.976994:  
2026-02-08 17:02:36.977247: Epoch 70 
2026-02-08 17:02:36.977397: Current learning rate: 0.00937 
2026-02-08 17:03:43.105417: train_loss -0.823 
2026-02-08 17:03:43.105886: val_loss -0.7947 
2026-02-08 17:03:43.105931: Pseudo dice [np.float32(0.8965)] 
2026-02-08 17:03:43.105987: Epoch time: 66.13 s 
2026-02-08 17:03:43.817351:  
2026-02-08 17:03:43.817552: Epoch 71 
2026-02-08 17:03:43.817706: Current learning rate: 0.00936 
2026-02-08 17:04:52.813304: train_loss -0.8543 
2026-02-08 17:04:52.813753: val_loss -0.8564 
2026-02-08 17:04:52.813799: Pseudo dice [np.float32(0.9137)] 
2026-02-08 17:04:52.813854: Epoch time: 69.0 s 
2026-02-08 17:04:53.505247:  
2026-02-08 17:04:53.505508: Epoch 72 
2026-02-08 17:04:53.505673: Current learning rate: 0.00935 
2026-02-08 17:05:59.151470: train_loss -0.8585 
2026-02-08 17:05:59.151855: val_loss -0.8506 
2026-02-08 17:05:59.151903: Pseudo dice [np.float32(0.9288)] 
2026-02-08 17:05:59.151960: Epoch time: 65.65 s 
2026-02-08 17:05:59.848466:  
2026-02-08 17:05:59.848698: Epoch 73 
2026-02-08 17:05:59.848797: Current learning rate: 0.00934 
2026-02-08 17:07:08.252048: train_loss -0.7491 
2026-02-08 17:07:08.252496: val_loss -0.8445 
2026-02-08 17:07:08.252573: Pseudo dice [np.float32(0.9106)] 
2026-02-08 17:07:08.252634: Epoch time: 68.4 s 
2026-02-08 17:07:08.965920:  
2026-02-08 17:07:08.966176: Epoch 74 
2026-02-08 17:07:08.966347: Current learning rate: 0.00933 
2026-02-08 17:08:17.829786: train_loss -0.8532 
2026-02-08 17:08:17.830223: val_loss -0.8191 
2026-02-08 17:08:17.830310: Pseudo dice [np.float32(0.8936)] 
2026-02-08 17:08:17.830373: Epoch time: 68.86 s 
2026-02-08 17:08:18.531413:  
2026-02-08 17:08:18.531584: Epoch 75 
2026-02-08 17:08:18.531680: Current learning rate: 0.00932 
2026-02-08 17:09:25.139355: train_loss -0.8484 
2026-02-08 17:09:25.139854: val_loss -0.7953 
2026-02-08 17:09:25.139900: Pseudo dice [np.float32(0.8873)] 
2026-02-08 17:09:25.139957: Epoch time: 66.61 s 
2026-02-08 17:09:25.852828:  
2026-02-08 17:09:25.853197: Epoch 76 
2026-02-08 17:09:25.853340: Current learning rate: 0.00931 
2026-02-08 17:10:33.596521: train_loss -0.8718 
2026-02-08 17:10:33.596962: val_loss -0.8194 
2026-02-08 17:10:33.597008: Pseudo dice [np.float32(0.9113)] 
2026-02-08 17:10:33.597062: Epoch time: 67.74 s 
2026-02-08 17:10:34.842950:  
2026-02-08 17:10:34.843129: Epoch 77 
2026-02-08 17:10:34.843237: Current learning rate: 0.0093 
2026-02-08 17:11:42.070322: train_loss -0.8291 
2026-02-08 17:11:42.070792: val_loss -0.8282 
2026-02-08 17:11:42.070838: Pseudo dice [np.float32(0.8987)] 
2026-02-08 17:11:42.070895: Epoch time: 67.23 s 
2026-02-08 17:11:42.777276:  
2026-02-08 17:11:42.777452: Epoch 78 
2026-02-08 17:11:42.777598: Current learning rate: 0.0093 
2026-02-08 17:12:49.072771: train_loss -0.8547 
2026-02-08 17:12:49.073223: val_loss -0.8098 
2026-02-08 17:12:49.073275: Pseudo dice [np.float32(0.8991)] 
2026-02-08 17:12:49.073332: Epoch time: 66.3 s 
2026-02-08 17:12:49.776691:  
2026-02-08 17:12:49.776947: Epoch 79 
2026-02-08 17:12:49.777046: Current learning rate: 0.00929 
2026-02-08 17:13:57.431411: train_loss -0.8385 
2026-02-08 17:13:57.431782: val_loss -0.8713 
2026-02-08 17:13:57.431877: Pseudo dice [np.float32(0.9334)] 
2026-02-08 17:13:57.431957: Epoch time: 67.66 s 
2026-02-08 17:13:58.140875:  
2026-02-08 17:13:58.141129: Epoch 80 
2026-02-08 17:13:58.141228: Current learning rate: 0.00928 
2026-02-08 17:15:04.989560: train_loss -0.8407 
2026-02-08 17:15:04.989936: val_loss -0.7839 
2026-02-08 17:15:04.989982: Pseudo dice [np.float32(0.8639)] 
2026-02-08 17:15:04.990036: Epoch time: 66.85 s 
2026-02-08 17:15:05.703637:  
2026-02-08 17:15:05.703950: Epoch 81 
2026-02-08 17:15:05.704053: Current learning rate: 0.00927 
2026-02-08 17:16:14.034256: train_loss -0.8272 
2026-02-08 17:16:14.034651: val_loss -0.8094 
2026-02-08 17:16:14.034729: Pseudo dice [np.float32(0.8743)] 
2026-02-08 17:16:14.035064: Epoch time: 68.33 s 
2026-02-08 17:16:14.740624:  
2026-02-08 17:16:14.740853: Epoch 82 
2026-02-08 17:16:14.740951: Current learning rate: 0.00926 
2026-02-08 17:17:25.792600: train_loss -0.7858 
2026-02-08 17:17:25.792953: val_loss -0.7775 
2026-02-08 17:17:25.792995: Pseudo dice [np.float32(0.863)] 
2026-02-08 17:17:25.793045: Epoch time: 71.05 s 
2026-02-08 17:17:26.470933:  
2026-02-08 17:17:26.471130: Epoch 83 
2026-02-08 17:17:26.471216: Current learning rate: 0.00925 
2026-02-08 17:18:32.402016: train_loss -0.8243 
2026-02-08 17:18:32.402379: val_loss -0.8059 
2026-02-08 17:18:32.402422: Pseudo dice [np.float32(0.8856)] 
2026-02-08 17:18:32.402473: Epoch time: 65.93 s 
2026-02-08 17:18:33.082522:  
2026-02-08 17:18:33.082717: Epoch 84 
2026-02-08 17:18:33.082815: Current learning rate: 0.00924 
2026-02-08 17:19:41.154746: train_loss -0.8247 
2026-02-08 17:19:41.155213: val_loss -0.879 
2026-02-08 17:19:41.155255: Pseudo dice [np.float32(0.9429)] 
2026-02-08 17:19:41.155316: Epoch time: 68.07 s 
2026-02-08 17:19:41.837446:  
2026-02-08 17:19:41.837590: Epoch 85 
2026-02-08 17:19:41.837686: Current learning rate: 0.00923 
2026-02-08 17:20:48.684925: train_loss -0.8537 
2026-02-08 17:20:48.685324: val_loss -0.8557 
2026-02-08 17:20:48.685370: Pseudo dice [np.float32(0.9209)] 
2026-02-08 17:20:48.685421: Epoch time: 66.85 s 
2026-02-08 17:20:49.367856:  
2026-02-08 17:20:49.368027: Epoch 86 
2026-02-08 17:20:49.368156: Current learning rate: 0.00922 
2026-02-08 17:21:57.705384: train_loss -0.8669 
2026-02-08 17:21:57.705778: val_loss -0.9034 
2026-02-08 17:21:57.705822: Pseudo dice [np.float32(0.9529)] 
2026-02-08 17:21:57.705873: Epoch time: 68.34 s 
2026-02-08 17:21:58.387017:  
2026-02-08 17:21:58.387237: Epoch 87 
2026-02-08 17:21:58.387382: Current learning rate: 0.00921 
2026-02-08 17:23:03.264296: train_loss -0.8203 
2026-02-08 17:23:03.264736: val_loss -0.8757 
2026-02-08 17:23:03.264780: Pseudo dice [np.float32(0.9377)] 
2026-02-08 17:23:03.264832: Epoch time: 64.88 s 
2026-02-08 17:23:03.945808:  
2026-02-08 17:23:03.946155: Epoch 88 
2026-02-08 17:23:03.946302: Current learning rate: 0.0092 
2026-02-08 17:24:10.403733: train_loss -0.8569 
2026-02-08 17:24:10.403993: val_loss -0.8579 
2026-02-08 17:24:10.404037: Pseudo dice [np.float32(0.9138)] 
2026-02-08 17:24:10.404091: Epoch time: 66.46 s 
2026-02-08 17:24:11.090600:  
2026-02-08 17:24:11.090800: Epoch 89 
2026-02-08 17:24:11.090902: Current learning rate: 0.0092 
2026-02-08 17:25:19.357241: train_loss -0.8276 
2026-02-08 17:25:19.357682: val_loss -0.8529 
2026-02-08 17:25:19.357725: Pseudo dice [np.float32(0.9195)] 
2026-02-08 17:25:19.357791: Epoch time: 68.27 s 
2026-02-08 17:25:20.039757:  
2026-02-08 17:25:20.039930: Epoch 90 
2026-02-08 17:25:20.040023: Current learning rate: 0.00919 
2026-02-08 17:26:27.916564: train_loss -0.8701 
2026-02-08 17:26:27.917069: val_loss -0.8379 
2026-02-08 17:26:27.917114: Pseudo dice [np.float32(0.9017)] 
2026-02-08 17:26:27.917169: Epoch time: 67.88 s 
2026-02-08 17:26:29.141991:  
2026-02-08 17:26:29.142184: Epoch 91 
2026-02-08 17:26:29.142302: Current learning rate: 0.00918 
2026-02-08 17:27:35.988277: train_loss -0.836 
2026-02-08 17:27:35.988729: val_loss -0.86 
2026-02-08 17:27:35.988777: Pseudo dice [np.float32(0.9177)] 
2026-02-08 17:27:35.988831: Epoch time: 66.85 s 
2026-02-08 17:27:36.673380:  
2026-02-08 17:27:36.673760: Epoch 92 
2026-02-08 17:27:36.673889: Current learning rate: 0.00917 
2026-02-08 17:28:44.401217: train_loss -0.8478 
2026-02-08 17:28:44.401609: val_loss -0.9108 
2026-02-08 17:28:44.401657: Pseudo dice [np.float32(0.9567)] 
2026-02-08 17:28:44.401714: Epoch time: 67.73 s 
2026-02-08 17:28:44.401761: Yayy! New best EMA pseudo Dice: 0.9161999821662903 
2026-02-08 17:28:45.492955:  
2026-02-08 17:28:45.493324: Epoch 93 
2026-02-08 17:28:45.493456: Current learning rate: 0.00916 
2026-02-08 17:29:52.745185: train_loss -0.8968 
2026-02-08 17:29:52.745664: val_loss -0.8625 
2026-02-08 17:29:52.745735: Pseudo dice [np.float32(0.9152)] 
2026-02-08 17:29:52.745797: Epoch time: 67.25 s 
2026-02-08 17:29:53.414322:  
2026-02-08 17:29:53.414474: Epoch 94 
2026-02-08 17:29:53.414574: Current learning rate: 0.00915 
2026-02-08 17:30:59.144216: train_loss -0.8289 
2026-02-08 17:30:59.144683: val_loss -0.862 
2026-02-08 17:30:59.144733: Pseudo dice [np.float32(0.9274)] 
2026-02-08 17:30:59.144794: Epoch time: 65.73 s 
2026-02-08 17:30:59.144830: Yayy! New best EMA pseudo Dice: 0.9172000288963318 
2026-02-08 17:31:00.197064:  
2026-02-08 17:31:00.197250: Epoch 95 
2026-02-08 17:31:00.197354: Current learning rate: 0.00914 
2026-02-08 17:32:03.205003: train_loss -0.8496 
2026-02-08 17:32:03.205449: val_loss -0.838 
2026-02-08 17:32:03.205496: Pseudo dice [np.float32(0.9069)] 
2026-02-08 17:32:03.205552: Epoch time: 63.01 s 
2026-02-08 17:32:03.884742:  
2026-02-08 17:32:03.884886: Epoch 96 
2026-02-08 17:32:03.884983: Current learning rate: 0.00913 
2026-02-08 17:33:11.288745: train_loss -0.8733 
2026-02-08 17:33:11.289210: val_loss -0.8683 
2026-02-08 17:33:11.289256: Pseudo dice [np.float32(0.9296)] 
2026-02-08 17:33:11.289324: Epoch time: 67.4 s 
2026-02-08 17:33:11.289360: Yayy! New best EMA pseudo Dice: 0.9175000190734863 
2026-02-08 17:33:12.366796:  
2026-02-08 17:33:12.367068: Epoch 97 
2026-02-08 17:33:12.367202: Current learning rate: 0.00912 
2026-02-08 17:34:20.526707: train_loss -0.8464 
2026-02-08 17:34:20.527120: val_loss -0.7589 
2026-02-08 17:34:20.527168: Pseudo dice [np.float32(0.8666)] 
2026-02-08 17:34:20.527223: Epoch time: 68.16 s 
2026-02-08 17:34:21.213396:  
2026-02-08 17:34:21.213627: Epoch 98 
2026-02-08 17:34:21.213732: Current learning rate: 0.00911 
2026-02-08 17:35:24.938260: train_loss -0.8616 
2026-02-08 17:35:24.938700: val_loss -0.8643 
2026-02-08 17:35:24.938747: Pseudo dice [np.float32(0.9265)] 
2026-02-08 17:35:24.938807: Epoch time: 63.73 s 
2026-02-08 17:35:25.610683:  
2026-02-08 17:35:25.610931: Epoch 99 
2026-02-08 17:35:25.611031: Current learning rate: 0.0091 
2026-02-08 17:36:33.849259: train_loss -0.8615 
2026-02-08 17:36:33.849769: val_loss -0.8282 
2026-02-08 17:36:33.849813: Pseudo dice [np.float32(0.9079)] 
2026-02-08 17:36:33.849869: Epoch time: 68.24 s 
2026-02-08 17:36:34.919345:  
2026-02-08 17:36:34.919714: Epoch 100 
2026-02-08 17:36:34.919811: Current learning rate: 0.0091 
2026-02-08 17:37:41.700724: train_loss -0.8406 
2026-02-08 17:37:41.701170: val_loss -0.7834 
2026-02-08 17:37:41.701216: Pseudo dice [np.float32(0.8675)] 
2026-02-08 17:37:41.701282: Epoch time: 66.78 s 
2026-02-08 17:37:42.378612:  
2026-02-08 17:37:42.378986: Epoch 101 
2026-02-08 17:37:42.379089: Current learning rate: 0.00909 
2026-02-08 17:38:47.961075: train_loss -0.8627 
2026-02-08 17:38:47.961483: val_loss -0.8399 
2026-02-08 17:38:47.961561: Pseudo dice [np.float32(0.8938)] 
2026-02-08 17:38:47.961642: Epoch time: 65.58 s 
2026-02-08 17:38:48.642681:  
2026-02-08 17:38:48.643053: Epoch 102 
2026-02-08 17:38:48.643149: Current learning rate: 0.00908 
2026-02-08 17:39:55.981142: train_loss -0.8396 
2026-02-08 17:39:55.981569: val_loss -0.8437 
2026-02-08 17:39:55.981649: Pseudo dice [np.float32(0.91)] 
2026-02-08 17:39:55.981708: Epoch time: 67.34 s 
2026-02-08 17:39:56.671212:  
2026-02-08 17:39:56.671615: Epoch 103 
2026-02-08 17:39:56.671721: Current learning rate: 0.00907 
2026-02-08 17:41:01.875991: train_loss -0.803 
2026-02-08 17:41:01.876425: val_loss -0.8131 
2026-02-08 17:41:01.876472: Pseudo dice [np.float32(0.895)] 
2026-02-08 17:41:01.876531: Epoch time: 65.21 s 
2026-02-08 17:41:02.560870:  
2026-02-08 17:41:02.561052: Epoch 104 
2026-02-08 17:41:02.561149: Current learning rate: 0.00906 
2026-02-08 17:42:10.118495: train_loss -0.8201 
2026-02-08 17:42:10.118886: val_loss -0.7651 
2026-02-08 17:42:10.118930: Pseudo dice [np.float32(0.8681)] 
2026-02-08 17:42:10.118979: Epoch time: 67.56 s 
2026-02-08 17:42:11.362049:  
2026-02-08 17:42:11.362348: Epoch 105 
2026-02-08 17:42:11.362481: Current learning rate: 0.00905 
2026-02-08 17:43:19.895783: train_loss -0.8337 
2026-02-08 17:43:19.896214: val_loss -0.8878 
2026-02-08 17:43:19.896260: Pseudo dice [np.float32(0.9467)] 
2026-02-08 17:43:19.896325: Epoch time: 68.53 s 
2026-02-08 17:43:20.571593:  
2026-02-08 17:43:20.571844: Epoch 106 
2026-02-08 17:43:20.572196: Current learning rate: 0.00904 
2026-02-08 17:44:26.293407: train_loss -0.8102 
2026-02-08 17:44:26.293822: val_loss -0.8055 
2026-02-08 17:44:26.293870: Pseudo dice [np.float32(0.8977)] 
2026-02-08 17:44:26.293924: Epoch time: 65.72 s 
2026-02-08 17:44:26.983800:  
2026-02-08 17:44:26.983951: Epoch 107 
2026-02-08 17:44:26.984044: Current learning rate: 0.00903 
2026-02-08 17:45:34.481161: train_loss -0.8743 
2026-02-08 17:45:34.481570: val_loss -0.8682 
2026-02-08 17:45:34.481616: Pseudo dice [np.float32(0.9325)] 
2026-02-08 17:45:34.481667: Epoch time: 67.5 s 
2026-02-08 17:45:35.174249:  
2026-02-08 17:45:35.174474: Epoch 108 
2026-02-08 17:45:35.174573: Current learning rate: 0.00902 
2026-02-08 17:46:42.690714: train_loss -0.8292 
2026-02-08 17:46:42.691147: val_loss -0.8288 
2026-02-08 17:46:42.691189: Pseudo dice [np.float32(0.898)] 
2026-02-08 17:46:42.691240: Epoch time: 67.52 s 
2026-02-08 17:46:43.368047:  
2026-02-08 17:46:43.368277: Epoch 109 
2026-02-08 17:46:43.368503: Current learning rate: 0.00901 
2026-02-08 17:47:49.381227: train_loss -0.8605 
2026-02-08 17:47:49.381623: val_loss -0.8386 
2026-02-08 17:47:49.381676: Pseudo dice [np.float32(0.905)] 
2026-02-08 17:47:49.381726: Epoch time: 66.01 s 
2026-02-08 17:47:50.060900:  
2026-02-08 17:47:50.061097: Epoch 110 
2026-02-08 17:47:50.061394: Current learning rate: 0.009 
2026-02-08 17:48:57.249995: train_loss -0.8514 
2026-02-08 17:48:57.250399: val_loss -0.8753 
2026-02-08 17:48:57.250443: Pseudo dice [np.float32(0.9356)] 
2026-02-08 17:48:57.250493: Epoch time: 67.19 s 
2026-02-08 17:48:57.941131:  
2026-02-08 17:48:57.941334: Epoch 111 
2026-02-08 17:48:57.941472: Current learning rate: 0.009 
2026-02-08 17:50:05.003162: train_loss -0.8794 
2026-02-08 17:50:05.003528: val_loss -0.8543 
2026-02-08 17:50:05.003695: Pseudo dice [np.float32(0.9242)] 
2026-02-08 17:50:05.003749: Epoch time: 67.06 s 
2026-02-08 17:50:05.679278:  
2026-02-08 17:50:05.679641: Epoch 112 
2026-02-08 17:50:05.679736: Current learning rate: 0.00899 
2026-02-08 17:51:09.558232: train_loss -0.8435 
2026-02-08 17:51:09.558602: val_loss -0.7466 
2026-02-08 17:51:09.558645: Pseudo dice [np.float32(0.8628)] 
2026-02-08 17:51:09.558694: Epoch time: 63.88 s 
2026-02-08 17:51:10.232776:  
2026-02-08 17:51:10.232971: Epoch 113 
2026-02-08 17:51:10.233129: Current learning rate: 0.00898 
2026-02-08 17:52:17.031440: train_loss -0.8253 
2026-02-08 17:52:17.031828: val_loss -0.8457 
2026-02-08 17:52:17.031870: Pseudo dice [np.float32(0.9294)] 
2026-02-08 17:52:17.031941: Epoch time: 66.8 s 
2026-02-08 17:52:17.710392:  
2026-02-08 17:52:17.710615: Epoch 114 
2026-02-08 17:52:17.710750: Current learning rate: 0.00897 
2026-02-08 17:53:21.941389: train_loss -0.856 
2026-02-08 17:53:21.941724: val_loss -0.8998 
2026-02-08 17:53:21.941806: Pseudo dice [np.float32(0.9517)] 
2026-02-08 17:53:21.941896: Epoch time: 64.23 s 
2026-02-08 17:53:22.626863:  
2026-02-08 17:53:22.627164: Epoch 115 
2026-02-08 17:53:22.627310: Current learning rate: 0.00896 
2026-02-08 17:54:29.054651: train_loss -0.853 
2026-02-08 17:54:29.055079: val_loss -0.8217 
2026-02-08 17:54:29.055123: Pseudo dice [np.float32(0.9108)] 
2026-02-08 17:54:29.055173: Epoch time: 66.43 s 
2026-02-08 17:54:29.759340:  
2026-02-08 17:54:29.759523: Epoch 116 
2026-02-08 17:54:29.759684: Current learning rate: 0.00895 
2026-02-08 17:55:34.480131: train_loss -0.8352 
2026-02-08 17:55:34.480463: val_loss -0.7942 
2026-02-08 17:55:34.480540: Pseudo dice [np.float32(0.8777)] 
2026-02-08 17:55:34.480591: Epoch time: 64.72 s 
2026-02-08 17:55:35.166662:  
2026-02-08 17:55:35.166881: Epoch 117 
2026-02-08 17:55:35.167097: Current learning rate: 0.00894 
2026-02-08 17:56:41.567616: train_loss -0.8548 
2026-02-08 17:56:41.567972: val_loss -0.8389 
2026-02-08 17:56:41.568014: Pseudo dice [np.float32(0.9247)] 
2026-02-08 17:56:41.568063: Epoch time: 66.4 s 
2026-02-08 17:56:42.253918:  
2026-02-08 17:56:42.254082: Epoch 118 
2026-02-08 17:56:42.254182: Current learning rate: 0.00893 
2026-02-08 17:57:50.806108: train_loss -0.8616 
2026-02-08 17:57:50.806518: val_loss -0.9047 
2026-02-08 17:57:50.806567: Pseudo dice [np.float32(0.9531)] 
2026-02-08 17:57:50.806619: Epoch time: 68.55 s 
2026-02-08 17:57:52.039888:  
2026-02-08 17:57:52.040223: Epoch 119 
2026-02-08 17:57:52.040344: Current learning rate: 0.00892 
2026-02-08 17:58:55.462802: train_loss -0.8706 
2026-02-08 17:58:55.463243: val_loss -0.8508 
2026-02-08 17:58:55.463302: Pseudo dice [np.float32(0.9232)] 
2026-02-08 17:58:55.463361: Epoch time: 63.42 s 
2026-02-08 17:58:56.146226:  
2026-02-08 17:58:56.146427: Epoch 120 
2026-02-08 17:58:56.146525: Current learning rate: 0.00891 
2026-02-08 18:00:04.777239: train_loss -0.8609 
2026-02-08 18:00:04.777596: val_loss -0.8584 
2026-02-08 18:00:04.777643: Pseudo dice [np.float32(0.9311)] 
2026-02-08 18:00:04.777696: Epoch time: 68.63 s 
2026-02-08 18:00:05.474746:  
2026-02-08 18:00:05.474896: Epoch 121 
2026-02-08 18:00:05.474993: Current learning rate: 0.0089 
2026-02-08 18:01:12.905409: train_loss -0.841 
2026-02-08 18:01:12.905797: val_loss -0.872 
2026-02-08 18:01:12.905842: Pseudo dice [np.float32(0.9282)] 
2026-02-08 18:01:12.905891: Epoch time: 67.43 s 
2026-02-08 18:01:12.905926: Yayy! New best EMA pseudo Dice: 0.9186000227928162 
2026-02-08 18:01:14.097706:  
2026-02-08 18:01:14.098034: Epoch 122 
2026-02-08 18:01:14.098159: Current learning rate: 0.00889 
2026-02-08 18:02:21.269351: train_loss -0.8288 
2026-02-08 18:02:21.269721: val_loss -0.8562 
2026-02-08 18:02:21.269764: Pseudo dice [np.float32(0.9246)] 
2026-02-08 18:02:21.269819: Epoch time: 67.17 s 
2026-02-08 18:02:21.269854: Yayy! New best EMA pseudo Dice: 0.9192000031471252 
2026-02-08 18:02:22.437068:  
2026-02-08 18:02:22.437230: Epoch 123 
2026-02-08 18:02:22.437331: Current learning rate: 0.00889 
2026-02-08 18:03:30.229998: train_loss -0.8074 
2026-02-08 18:03:30.230358: val_loss -0.8024 
2026-02-08 18:03:30.230432: Pseudo dice [np.float32(0.8752)] 
2026-02-08 18:03:30.230487: Epoch time: 67.79 s 
2026-02-08 18:03:30.922716:  
2026-02-08 18:03:30.922920: Epoch 124 
2026-02-08 18:03:30.923017: Current learning rate: 0.00888 
2026-02-08 18:04:36.180231: train_loss -0.8082 
2026-02-08 18:04:36.180632: val_loss -0.8718 
2026-02-08 18:04:36.180676: Pseudo dice [np.float32(0.9397)] 
2026-02-08 18:04:36.180726: Epoch time: 65.26 s 
2026-02-08 18:04:36.872841:  
2026-02-08 18:04:36.873088: Epoch 125 
2026-02-08 18:04:36.873190: Current learning rate: 0.00887 
2026-02-08 18:05:44.161431: train_loss -0.8543 
2026-02-08 18:05:44.161867: val_loss -0.8178 
2026-02-08 18:05:44.161910: Pseudo dice [np.float32(0.8975)] 
2026-02-08 18:05:44.161957: Epoch time: 67.29 s 
2026-02-08 18:05:44.850055:  
2026-02-08 18:05:44.850291: Epoch 126 
2026-02-08 18:05:44.850389: Current learning rate: 0.00886 
2026-02-08 18:06:52.895309: train_loss -0.8779 
2026-02-08 18:06:52.895700: val_loss -0.8738 
2026-02-08 18:06:52.895746: Pseudo dice [np.float32(0.9303)] 
2026-02-08 18:06:52.895801: Epoch time: 68.05 s 
2026-02-08 18:06:53.582893:  
2026-02-08 18:06:53.583152: Epoch 127 
2026-02-08 18:06:53.583325: Current learning rate: 0.00885 
2026-02-08 18:08:00.079109: train_loss -0.8679 
2026-02-08 18:08:00.079503: val_loss -0.8683 
2026-02-08 18:08:00.079600: Pseudo dice [np.float32(0.936)] 
2026-02-08 18:08:00.079663: Epoch time: 66.5 s 
2026-02-08 18:08:00.773618:  
2026-02-08 18:08:00.773829: Epoch 128 
2026-02-08 18:08:00.773962: Current learning rate: 0.00884 
2026-02-08 18:09:06.261713: train_loss -0.8583 
2026-02-08 18:09:06.262188: val_loss -0.893 
2026-02-08 18:09:06.262233: Pseudo dice [np.float32(0.9451)] 
2026-02-08 18:09:06.262302: Epoch time: 65.49 s 
2026-02-08 18:09:06.262342: Yayy! New best EMA pseudo Dice: 0.9212999939918518 
2026-02-08 18:09:07.370588:  
2026-02-08 18:09:07.370886: Epoch 129 
2026-02-08 18:09:07.371047: Current learning rate: 0.00883 
2026-02-08 18:10:11.980387: train_loss -0.8802 
2026-02-08 18:10:11.980856: val_loss -0.8732 
2026-02-08 18:10:11.980904: Pseudo dice [np.float32(0.9343)] 
2026-02-08 18:10:11.980965: Epoch time: 64.61 s 
2026-02-08 18:10:11.980999: Yayy! New best EMA pseudo Dice: 0.9225999712944031 
2026-02-08 18:10:13.066669:  
2026-02-08 18:10:13.067001: Epoch 130 
2026-02-08 18:10:13.067098: Current learning rate: 0.00882 
2026-02-08 18:11:18.960827: train_loss -0.8508 
2026-02-08 18:11:18.961310: val_loss -0.7917 
2026-02-08 18:11:18.961359: Pseudo dice [np.float32(0.8981)] 
2026-02-08 18:11:18.961425: Epoch time: 65.89 s 
2026-02-08 18:11:19.662384:  
2026-02-08 18:11:19.662665: Epoch 131 
2026-02-08 18:11:19.662764: Current learning rate: 0.00881 
2026-02-08 18:12:25.874759: train_loss -0.8411 
2026-02-08 18:12:25.875239: val_loss -0.8429 
2026-02-08 18:12:25.875299: Pseudo dice [np.float32(0.9307)] 
2026-02-08 18:12:25.875362: Epoch time: 66.21 s 
2026-02-08 18:12:26.560529:  
2026-02-08 18:12:26.560646: Epoch 132 
2026-02-08 18:12:26.560740: Current learning rate: 0.0088 
2026-02-08 18:13:31.465213: train_loss -0.8646 
2026-02-08 18:13:31.465623: val_loss -0.874 
2026-02-08 18:13:31.465668: Pseudo dice [np.float32(0.923)] 
2026-02-08 18:13:31.465725: Epoch time: 64.91 s 
2026-02-08 18:13:32.709918:  
2026-02-08 18:13:32.710309: Epoch 133 
2026-02-08 18:13:32.710435: Current learning rate: 0.00879 
2026-02-08 18:14:38.055189: train_loss -0.8578 
2026-02-08 18:14:38.055618: val_loss -0.8314 
2026-02-08 18:14:38.055663: Pseudo dice [np.float32(0.8975)] 
2026-02-08 18:14:38.055727: Epoch time: 65.35 s 
2026-02-08 18:14:38.744793:  
2026-02-08 18:14:38.745008: Epoch 134 
2026-02-08 18:14:38.745116: Current learning rate: 0.00879 
2026-02-08 18:15:44.201507: train_loss -0.8225 
2026-02-08 18:15:44.201893: val_loss -0.8952 
2026-02-08 18:15:44.202076: Pseudo dice [np.float32(0.9513)] 
2026-02-08 18:15:44.202143: Epoch time: 65.46 s 
2026-02-08 18:15:44.893404:  
2026-02-08 18:15:44.893644: Epoch 135 
2026-02-08 18:15:44.893770: Current learning rate: 0.00878 
2026-02-08 18:16:49.301090: train_loss -0.8628 
2026-02-08 18:16:49.301562: val_loss -0.8743 
2026-02-08 18:16:49.301648: Pseudo dice [np.float32(0.9355)] 
2026-02-08 18:16:49.301714: Epoch time: 64.41 s 
2026-02-08 18:16:49.301754: Yayy! New best EMA pseudo Dice: 0.9236000180244446 
2026-02-08 18:16:50.469259:  
2026-02-08 18:16:50.469474: Epoch 136 
2026-02-08 18:16:50.469582: Current learning rate: 0.00877 
2026-02-08 18:17:56.765114: train_loss -0.8687 
2026-02-08 18:17:56.765481: val_loss -0.9125 
2026-02-08 18:17:56.765630: Pseudo dice [np.float32(0.9586)] 
2026-02-08 18:17:56.765738: Epoch time: 66.3 s 
2026-02-08 18:17:56.765782: Yayy! New best EMA pseudo Dice: 0.9271000027656555 
2026-02-08 18:17:57.914459:  
2026-02-08 18:17:57.914710: Epoch 137 
2026-02-08 18:17:57.914806: Current learning rate: 0.00876 
2026-02-08 18:19:02.585310: train_loss -0.8744 
2026-02-08 18:19:02.585742: val_loss -0.8961 
2026-02-08 18:19:02.585790: Pseudo dice [np.float32(0.9394)] 
2026-02-08 18:19:02.585849: Epoch time: 64.67 s 
2026-02-08 18:19:02.585887: Yayy! New best EMA pseudo Dice: 0.9283000230789185 
2026-02-08 18:19:03.728022:  
2026-02-08 18:19:03.728196: Epoch 138 
2026-02-08 18:19:03.728302: Current learning rate: 0.00875 
2026-02-08 18:20:10.617076: train_loss -0.864 
2026-02-08 18:20:10.617481: val_loss -0.8851 
2026-02-08 18:20:10.617527: Pseudo dice [np.float32(0.9273)] 
2026-02-08 18:20:10.617585: Epoch time: 66.89 s 
2026-02-08 18:20:11.330967:  
2026-02-08 18:20:11.331159: Epoch 139 
2026-02-08 18:20:11.331257: Current learning rate: 0.00874 
2026-02-08 18:21:17.531919: train_loss -0.8521 
2026-02-08 18:21:17.532340: val_loss -0.8435 
2026-02-08 18:21:17.532386: Pseudo dice [np.float32(0.9138)] 
2026-02-08 18:21:17.532439: Epoch time: 66.2 s 
2026-02-08 18:21:18.226565:  
2026-02-08 18:21:18.226752: Epoch 140 
2026-02-08 18:21:18.226851: Current learning rate: 0.00873 
2026-02-08 18:22:23.827409: train_loss -0.8726 
2026-02-08 18:22:23.827844: val_loss -0.8624 
2026-02-08 18:22:23.827890: Pseudo dice [np.float32(0.9301)] 
2026-02-08 18:22:23.827946: Epoch time: 65.6 s 
2026-02-08 18:22:24.535088:  
2026-02-08 18:22:24.535501: Epoch 141 
2026-02-08 18:22:24.535600: Current learning rate: 0.00872 
2026-02-08 18:23:31.312709: train_loss -0.856 
2026-02-08 18:23:31.313097: val_loss -0.8866 
2026-02-08 18:23:31.313140: Pseudo dice [np.float32(0.9402)] 
2026-02-08 18:23:31.313188: Epoch time: 66.78 s 
2026-02-08 18:23:31.313222: Yayy! New best EMA pseudo Dice: 0.9283999800682068 
2026-02-08 18:23:32.441231:  
2026-02-08 18:23:32.441375: Epoch 142 
2026-02-08 18:23:32.441467: Current learning rate: 0.00871 
2026-02-08 18:24:40.220250: train_loss -0.8395 
2026-02-08 18:24:40.220687: val_loss -0.8235 
2026-02-08 18:24:40.220729: Pseudo dice [np.float32(0.9055)] 
2026-02-08 18:24:40.220782: Epoch time: 67.78 s 
2026-02-08 18:24:40.922132:  
2026-02-08 18:24:40.922334: Epoch 143 
2026-02-08 18:24:40.922477: Current learning rate: 0.0087 
2026-02-08 18:25:48.079977: train_loss -0.8612 
2026-02-08 18:25:48.080447: val_loss -0.8125 
2026-02-08 18:25:48.080496: Pseudo dice [np.float32(0.9057)] 
2026-02-08 18:25:48.080555: Epoch time: 67.16 s 
2026-02-08 18:25:48.774113:  
2026-02-08 18:25:48.774337: Epoch 144 
2026-02-08 18:25:48.774467: Current learning rate: 0.00869 
2026-02-08 18:26:54.437620: train_loss -0.8704 
2026-02-08 18:26:54.438048: val_loss -0.7976 
2026-02-08 18:26:54.438095: Pseudo dice [np.float32(0.8896)] 
2026-02-08 18:26:54.438152: Epoch time: 65.66 s 
2026-02-08 18:26:55.129048:  
2026-02-08 18:26:55.129263: Epoch 145 
2026-02-08 18:26:55.129375: Current learning rate: 0.00868 
2026-02-08 18:28:00.215117: train_loss -0.8807 
2026-02-08 18:28:00.215438: val_loss -0.8987 
2026-02-08 18:28:00.215485: Pseudo dice [np.float32(0.9494)] 
2026-02-08 18:28:00.215544: Epoch time: 65.09 s 
2026-02-08 18:28:00.929686:  
2026-02-08 18:28:00.929893: Epoch 146 
2026-02-08 18:28:00.930035: Current learning rate: 0.00868 
2026-02-08 18:29:07.562002: train_loss -0.8854 
2026-02-08 18:29:07.562471: val_loss -0.9259 
2026-02-08 18:29:07.562514: Pseudo dice [np.float32(0.9609)] 
2026-02-08 18:29:07.562567: Epoch time: 66.63 s 
2026-02-08 18:29:08.822520:  
2026-02-08 18:29:08.822732: Epoch 147 
2026-02-08 18:29:08.822862: Current learning rate: 0.00867 
2026-02-08 18:30:13.714515: train_loss -0.8518 
2026-02-08 18:30:13.714925: val_loss -0.8673 
2026-02-08 18:30:13.715009: Pseudo dice [np.float32(0.9284)] 
2026-02-08 18:30:13.715072: Epoch time: 64.89 s 
2026-02-08 18:30:14.408242:  
2026-02-08 18:30:14.408478: Epoch 148 
2026-02-08 18:30:14.408579: Current learning rate: 0.00866 
2026-02-08 18:31:22.224101: train_loss -0.868 
2026-02-08 18:31:22.224535: val_loss -0.8735 
2026-02-08 18:31:22.224596: Pseudo dice [np.float32(0.9346)] 
2026-02-08 18:31:22.224653: Epoch time: 67.82 s 
2026-02-08 18:31:22.921925:  
2026-02-08 18:31:22.922122: Epoch 149 
2026-02-08 18:31:22.922452: Current learning rate: 0.00865 
2026-02-08 18:32:31.299338: train_loss -0.8841 
2026-02-08 18:32:31.299768: val_loss -0.8028 
2026-02-08 18:32:31.299816: Pseudo dice [np.float32(0.8933)] 
2026-02-08 18:32:31.299874: Epoch time: 68.38 s 
2026-02-08 18:32:32.432643:  
2026-02-08 18:32:32.432869: Epoch 150 
2026-02-08 18:32:32.433002: Current learning rate: 0.00864 
2026-02-08 18:33:38.876168: train_loss -0.9 
2026-02-08 18:33:38.876606: val_loss -0.8984 
2026-02-08 18:33:38.876716: Pseudo dice [np.float32(0.939)] 
2026-02-08 18:33:38.876780: Epoch time: 66.44 s 
2026-02-08 18:33:39.575314:  
2026-02-08 18:33:39.575531: Epoch 151 
2026-02-08 18:33:39.575629: Current learning rate: 0.00863 
2026-02-08 18:34:49.811194: train_loss -0.8501 
2026-02-08 18:34:49.811657: val_loss -0.8282 
2026-02-08 18:34:49.811705: Pseudo dice [np.float32(0.9114)] 
2026-02-08 18:34:49.811760: Epoch time: 70.24 s 
2026-02-08 18:34:50.509339:  
2026-02-08 18:34:50.509701: Epoch 152 
2026-02-08 18:34:50.509805: Current learning rate: 0.00862 
2026-02-08 18:36:00.563762: train_loss -0.8789 
2026-02-08 18:36:00.564214: val_loss -0.9162 
2026-02-08 18:36:00.564260: Pseudo dice [np.float32(0.9606)] 
2026-02-08 18:36:00.564319: Epoch time: 70.06 s 
2026-02-08 18:36:01.278226:  
2026-02-08 18:36:01.278392: Epoch 153 
2026-02-08 18:36:01.278487: Current learning rate: 0.00861 
2026-02-08 18:37:05.704176: train_loss -0.885 
2026-02-08 18:37:05.704531: val_loss -0.8852 
2026-02-08 18:37:05.704612: Pseudo dice [np.float32(0.9392)] 
2026-02-08 18:37:05.704665: Epoch time: 64.43 s 
2026-02-08 18:37:05.704700: Yayy! New best EMA pseudo Dice: 0.9293000102043152 
2026-02-08 18:37:06.877253:  
2026-02-08 18:37:06.877469: Epoch 154 
2026-02-08 18:37:06.877811: Current learning rate: 0.0086 
2026-02-08 18:38:12.654415: train_loss -0.8706 
2026-02-08 18:38:12.654811: val_loss -0.9041 
2026-02-08 18:38:12.654852: Pseudo dice [np.float32(0.9445)] 
2026-02-08 18:38:12.654903: Epoch time: 65.78 s 
2026-02-08 18:38:12.654937: Yayy! New best EMA pseudo Dice: 0.9308000206947327 
2026-02-08 18:38:13.815089:  
2026-02-08 18:38:13.815254: Epoch 155 
2026-02-08 18:38:13.815440: Current learning rate: 0.00859 
2026-02-08 18:39:24.232783: train_loss -0.8828 
2026-02-08 18:39:24.233193: val_loss -0.9151 
2026-02-08 18:39:24.233235: Pseudo dice [np.float32(0.9578)] 
2026-02-08 18:39:24.233297: Epoch time: 70.42 s 
2026-02-08 18:39:24.233336: Yayy! New best EMA pseudo Dice: 0.9334999918937683 
2026-02-08 18:39:25.392182:  
2026-02-08 18:39:25.392425: Epoch 156 
2026-02-08 18:39:25.392525: Current learning rate: 0.00858 
2026-02-08 18:40:33.802912: train_loss -0.844 
2026-02-08 18:40:33.803296: val_loss -0.8411 
2026-02-08 18:40:33.803396: Pseudo dice [np.float32(0.9161)] 
2026-02-08 18:40:33.803450: Epoch time: 68.41 s 
2026-02-08 18:40:34.520386:  
2026-02-08 18:40:34.520582: Epoch 157 
2026-02-08 18:40:34.520680: Current learning rate: 0.00858 
2026-02-08 18:41:41.811876: train_loss -0.8958 
2026-02-08 18:41:41.812227: val_loss -0.8898 
2026-02-08 18:41:41.812332: Pseudo dice [np.float32(0.9404)] 
2026-02-08 18:41:41.812386: Epoch time: 67.29 s 
2026-02-08 18:41:42.510074:  
2026-02-08 18:41:42.510314: Epoch 158 
2026-02-08 18:41:42.510414: Current learning rate: 0.00857 
2026-02-08 18:42:51.038576: train_loss -0.9002 
2026-02-08 18:42:51.038937: val_loss -0.9037 
2026-02-08 18:42:51.039040: Pseudo dice [np.float32(0.949)] 
2026-02-08 18:42:51.039093: Epoch time: 68.53 s 
2026-02-08 18:42:51.039129: Yayy! New best EMA pseudo Dice: 0.9343000054359436 
2026-02-08 18:42:52.203882:  
2026-02-08 18:42:52.204292: Epoch 159 
2026-02-08 18:42:52.204392: Current learning rate: 0.00856 
2026-02-08 18:43:56.494651: train_loss -0.8883 
2026-02-08 18:43:56.495068: val_loss -0.85 
2026-02-08 18:43:56.495109: Pseudo dice [np.float32(0.8993)] 
2026-02-08 18:43:56.495158: Epoch time: 64.29 s 
2026-02-08 18:43:57.202957:  
2026-02-08 18:43:57.203199: Epoch 160 
2026-02-08 18:43:57.203306: Current learning rate: 0.00855 
2026-02-08 18:45:04.101170: train_loss -0.8872 
2026-02-08 18:45:04.101621: val_loss -0.8979 
2026-02-08 18:45:04.101665: Pseudo dice [np.float32(0.9521)] 
2026-02-08 18:45:04.101717: Epoch time: 66.9 s 
2026-02-08 18:45:05.371126:  
2026-02-08 18:45:05.371295: Epoch 161 
2026-02-08 18:45:05.371391: Current learning rate: 0.00854 
2026-02-08 18:46:11.947877: train_loss -0.8464 
2026-02-08 18:46:11.948297: val_loss -0.8716 
2026-02-08 18:46:11.948351: Pseudo dice [np.float32(0.9317)] 
2026-02-08 18:46:11.948410: Epoch time: 66.58 s 
2026-02-08 18:46:12.641484:  
2026-02-08 18:46:12.641711: Epoch 162 
2026-02-08 18:46:12.641810: Current learning rate: 0.00853 
2026-02-08 18:47:16.103307: train_loss -0.8512 
2026-02-08 18:47:16.103637: val_loss -0.8791 
2026-02-08 18:47:16.103740: Pseudo dice [np.float32(0.9402)] 
2026-02-08 18:47:16.103868: Epoch time: 63.46 s 
2026-02-08 18:47:16.810062:  
2026-02-08 18:47:16.810319: Epoch 163 
2026-02-08 18:47:16.810419: Current learning rate: 0.00852 
2026-02-08 18:48:25.325339: train_loss -0.8533 
2026-02-08 18:48:25.325763: val_loss -0.7887 
2026-02-08 18:48:25.325808: Pseudo dice [np.float32(0.8793)] 
2026-02-08 18:48:25.325859: Epoch time: 68.52 s 
2026-02-08 18:48:26.035964:  
2026-02-08 18:48:26.036136: Epoch 164 
2026-02-08 18:48:26.036233: Current learning rate: 0.00851 
2026-02-08 18:49:34.895525: train_loss -0.8681 
2026-02-08 18:49:34.895999: val_loss -0.9096 
2026-02-08 18:49:34.896043: Pseudo dice [np.float32(0.9573)] 
2026-02-08 18:49:34.896103: Epoch time: 68.86 s 
2026-02-08 18:49:35.593940:  
2026-02-08 18:49:35.594091: Epoch 165 
2026-02-08 18:49:35.594185: Current learning rate: 0.0085 
2026-02-08 18:50:39.807306: train_loss -0.8748 
2026-02-08 18:50:39.807752: val_loss -0.8372 
2026-02-08 18:50:39.807810: Pseudo dice [np.float32(0.896)] 
2026-02-08 18:50:39.807869: Epoch time: 64.21 s 
2026-02-08 18:50:40.513893:  
2026-02-08 18:50:40.514163: Epoch 166 
2026-02-08 18:50:40.514276: Current learning rate: 0.00849 
2026-02-08 18:51:47.822833: train_loss -0.8681 
2026-02-08 18:51:47.823225: val_loss -0.8736 
2026-02-08 18:51:47.823295: Pseudo dice [np.float32(0.9272)] 
2026-02-08 18:51:47.823358: Epoch time: 67.31 s 
2026-02-08 18:51:48.528028:  
2026-02-08 18:51:48.528277: Epoch 167 
2026-02-08 18:51:48.528380: Current learning rate: 0.00848 
2026-02-08 18:52:53.383773: train_loss -0.8268 
2026-02-08 18:52:53.384156: val_loss -0.8453 
2026-02-08 18:52:53.384202: Pseudo dice [np.float32(0.9256)] 
2026-02-08 18:52:53.384259: Epoch time: 64.86 s 
2026-02-08 18:52:54.091189:  
2026-02-08 18:52:54.091444: Epoch 168 
2026-02-08 18:52:54.091630: Current learning rate: 0.00847 
2026-02-08 18:54:01.959795: train_loss -0.8368 
2026-02-08 18:54:01.960237: val_loss -0.851 
2026-02-08 18:54:01.960293: Pseudo dice [np.float32(0.9126)] 
2026-02-08 18:54:01.960351: Epoch time: 67.87 s 
2026-02-08 18:54:02.671196:  
2026-02-08 18:54:02.671499: Epoch 169 
2026-02-08 18:54:02.671596: Current learning rate: 0.00847 
2026-02-08 18:55:10.703435: train_loss -0.8583 
2026-02-08 18:55:10.703928: val_loss -0.855 
2026-02-08 18:55:10.703976: Pseudo dice [np.float32(0.9256)] 
2026-02-08 18:55:10.704031: Epoch time: 68.03 s 
2026-02-08 18:55:11.417966:  
2026-02-08 18:55:11.418358: Epoch 170 
2026-02-08 18:55:11.418522: Current learning rate: 0.00846 
2026-02-08 18:56:15.912135: train_loss -0.8854 
2026-02-08 18:56:15.912637: val_loss -0.8846 
2026-02-08 18:56:15.912681: Pseudo dice [np.float32(0.9419)] 
2026-02-08 18:56:15.912736: Epoch time: 64.49 s 
2026-02-08 18:56:16.625834:  
2026-02-08 18:56:16.626015: Epoch 171 
2026-02-08 18:56:16.626122: Current learning rate: 0.00845 
2026-02-08 18:57:21.314817: train_loss -0.8512 
2026-02-08 18:57:21.315312: val_loss -0.8567 
2026-02-08 18:57:21.315358: Pseudo dice [np.float32(0.9228)] 
2026-02-08 18:57:21.315414: Epoch time: 64.69 s 
2026-02-08 18:57:22.011754:  
2026-02-08 18:57:22.011969: Epoch 172 
2026-02-08 18:57:22.012064: Current learning rate: 0.00844 
2026-02-08 18:58:27.739444: train_loss -0.8617 
2026-02-08 18:58:27.739762: val_loss -0.8959 
2026-02-08 18:58:27.739847: Pseudo dice [np.float32(0.9379)] 
2026-02-08 18:58:27.739904: Epoch time: 65.73 s 
2026-02-08 18:58:28.440430:  
2026-02-08 18:58:28.440579: Epoch 173 
2026-02-08 18:58:28.440677: Current learning rate: 0.00843 
2026-02-08 18:59:35.721754: train_loss -0.8761 
2026-02-08 18:59:35.722175: val_loss -0.9073 
2026-02-08 18:59:35.722224: Pseudo dice [np.float32(0.9539)] 
2026-02-08 18:59:35.722285: Epoch time: 67.28 s 
2026-02-08 18:59:36.965568:  
2026-02-08 18:59:36.965788: Epoch 174 
2026-02-08 18:59:36.965884: Current learning rate: 0.00842 
2026-02-08 19:00:44.549261: train_loss -0.8771 
2026-02-08 19:00:44.549670: val_loss -0.8831 
2026-02-08 19:00:44.549753: Pseudo dice [np.float32(0.9378)] 
2026-02-08 19:00:44.549842: Epoch time: 67.58 s 
2026-02-08 19:00:45.245859:  
2026-02-08 19:00:45.246073: Epoch 175 
2026-02-08 19:00:45.246172: Current learning rate: 0.00841 
2026-02-08 19:01:49.034519: train_loss -0.8712 
2026-02-08 19:01:49.034926: val_loss -0.881 
2026-02-08 19:01:49.034971: Pseudo dice [np.float32(0.9391)] 
2026-02-08 19:01:49.035030: Epoch time: 63.79 s 
2026-02-08 19:01:49.732447:  
2026-02-08 19:01:49.732736: Epoch 176 
2026-02-08 19:01:49.732838: Current learning rate: 0.0084 
2026-02-08 19:02:55.455302: train_loss -0.8628 
2026-02-08 19:02:55.455637: val_loss -0.8893 
2026-02-08 19:02:55.455746: Pseudo dice [np.float32(0.9336)] 
2026-02-08 19:02:55.455817: Epoch time: 65.72 s 
2026-02-08 19:02:56.152788:  
2026-02-08 19:02:56.153068: Epoch 177 
2026-02-08 19:02:56.153218: Current learning rate: 0.00839 
2026-02-08 19:04:02.833321: train_loss -0.9129 
2026-02-08 19:04:02.833751: val_loss -0.8631 
2026-02-08 19:04:02.833803: Pseudo dice [np.float32(0.9213)] 
2026-02-08 19:04:02.833853: Epoch time: 66.68 s 
2026-02-08 19:04:03.532380:  
2026-02-08 19:04:03.532705: Epoch 178 
2026-02-08 19:04:03.532802: Current learning rate: 0.00838 
2026-02-08 19:05:09.420762: train_loss -0.8846 
2026-02-08 19:05:09.421369: val_loss -0.8897 
2026-02-08 19:05:09.421421: Pseudo dice [np.float32(0.9437)] 
2026-02-08 19:05:09.421474: Epoch time: 65.89 s 
2026-02-08 19:05:10.128033:  
2026-02-08 19:05:10.128437: Epoch 179 
2026-02-08 19:05:10.128538: Current learning rate: 0.00837 
2026-02-08 19:06:18.535232: train_loss -0.8605 
2026-02-08 19:06:18.535675: val_loss -0.93 
2026-02-08 19:06:18.535719: Pseudo dice [np.float32(0.9675)] 
2026-02-08 19:06:18.535770: Epoch time: 68.41 s 
2026-02-08 19:06:18.535808: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2026-02-08 19:06:19.682877:  
2026-02-08 19:06:19.683105: Epoch 180 
2026-02-08 19:06:19.683280: Current learning rate: 0.00836 
2026-02-08 19:07:24.809952: train_loss -0.8589 
2026-02-08 19:07:24.810422: val_loss -0.8685 
2026-02-08 19:07:24.810472: Pseudo dice [np.float32(0.9172)] 
2026-02-08 19:07:24.810531: Epoch time: 65.13 s 
2026-02-08 19:07:25.524551:  
2026-02-08 19:07:25.524828: Epoch 181 
2026-02-08 19:07:25.524930: Current learning rate: 0.00836 
2026-02-08 19:08:32.631224: train_loss -0.8356 
2026-02-08 19:08:32.631690: val_loss -0.859 
2026-02-08 19:08:32.631734: Pseudo dice [np.float32(0.918)] 
2026-02-08 19:08:32.631788: Epoch time: 67.11 s 
2026-02-08 19:08:33.338521:  
2026-02-08 19:08:33.338767: Epoch 182 
2026-02-08 19:08:33.338867: Current learning rate: 0.00835 
2026-02-08 19:09:40.281358: train_loss -0.8723 
2026-02-08 19:09:40.281798: val_loss -0.875 
2026-02-08 19:09:40.281843: Pseudo dice [np.float32(0.9305)] 
2026-02-08 19:09:40.281901: Epoch time: 66.94 s 
2026-02-08 19:09:40.973912:  
2026-02-08 19:09:40.974095: Epoch 183 
2026-02-08 19:09:40.974195: Current learning rate: 0.00834 
2026-02-08 19:10:45.073672: train_loss -0.9009 
2026-02-08 19:10:45.074161: val_loss -0.8772 
2026-02-08 19:10:45.074210: Pseudo dice [np.float32(0.9444)] 
2026-02-08 19:10:45.074274: Epoch time: 64.1 s 
2026-02-08 19:10:45.786232:  
2026-02-08 19:10:45.786513: Epoch 184 
2026-02-08 19:10:45.786635: Current learning rate: 0.00833 
2026-02-08 19:11:52.153593: train_loss -0.8872 
2026-02-08 19:11:52.153940: val_loss -0.8947 
2026-02-08 19:11:52.153984: Pseudo dice [np.float32(0.945)] 
2026-02-08 19:11:52.154038: Epoch time: 66.37 s 
2026-02-08 19:11:52.856885:  
2026-02-08 19:11:52.857125: Epoch 185 
2026-02-08 19:11:52.857224: Current learning rate: 0.00832 
2026-02-08 19:12:59.045650: train_loss -0.8647 
2026-02-08 19:12:59.046022: val_loss -0.8917 
2026-02-08 19:12:59.046068: Pseudo dice [np.float32(0.9382)] 
2026-02-08 19:12:59.046125: Epoch time: 66.19 s 
2026-02-08 19:12:59.749912:  
2026-02-08 19:12:59.750144: Epoch 186 
2026-02-08 19:12:59.750266: Current learning rate: 0.00831 
2026-02-08 19:14:05.226254: train_loss -0.8769 
2026-02-08 19:14:05.226606: val_loss -0.8693 
2026-02-08 19:14:05.226648: Pseudo dice [np.float32(0.9343)] 
2026-02-08 19:14:05.226696: Epoch time: 65.48 s 
2026-02-08 19:14:05.916840:  
2026-02-08 19:14:05.917138: Epoch 187 
2026-02-08 19:14:05.917239: Current learning rate: 0.0083 
2026-02-08 19:15:11.380415: train_loss -0.8907 
2026-02-08 19:15:11.387131: val_loss -0.819 
2026-02-08 19:15:11.387206: Pseudo dice [np.float32(0.9062)] 
2026-02-08 19:15:11.387337: Epoch time: 65.46 s 
2026-02-08 19:15:12.636490:  
2026-02-08 19:15:12.636650: Epoch 188 
2026-02-08 19:15:12.636747: Current learning rate: 0.00829 
2026-02-08 19:16:17.678720: train_loss -0.8669 
2026-02-08 19:16:17.679118: val_loss -0.8923 
2026-02-08 19:16:17.679165: Pseudo dice [np.float32(0.9442)] 
2026-02-08 19:16:17.679226: Epoch time: 65.04 s 
2026-02-08 19:16:18.375745:  
2026-02-08 19:16:18.375995: Epoch 189 
2026-02-08 19:16:18.376092: Current learning rate: 0.00828 
2026-02-08 19:17:24.205985: train_loss -0.8979 
2026-02-08 19:17:24.206452: val_loss -0.9008 
2026-02-08 19:17:24.206499: Pseudo dice [np.float32(0.9484)] 
2026-02-08 19:17:24.206548: Epoch time: 65.83 s 
2026-02-08 19:17:24.902225:  
2026-02-08 19:17:24.902649: Epoch 190 
2026-02-08 19:17:24.902758: Current learning rate: 0.00827 
2026-02-08 19:18:31.331977: train_loss -0.8834 
2026-02-08 19:18:31.332320: val_loss -0.8888 
2026-02-08 19:18:31.332409: Pseudo dice [np.float32(0.9374)] 
2026-02-08 19:18:31.332522: Epoch time: 66.43 s 
2026-02-08 19:18:32.032289:  
2026-02-08 19:18:32.032629: Epoch 191 
2026-02-08 19:18:32.032774: Current learning rate: 0.00826 
2026-02-08 19:19:39.005636: train_loss -0.8735 
2026-02-08 19:19:39.006009: val_loss -0.8886 
2026-02-08 19:19:39.006062: Pseudo dice [np.float32(0.9427)] 
2026-02-08 19:19:39.006116: Epoch time: 66.97 s 
2026-02-08 19:19:39.708095:  
2026-02-08 19:19:39.708332: Epoch 192 
2026-02-08 19:19:39.708441: Current learning rate: 0.00825 
2026-02-08 19:20:46.120650: train_loss -0.9037 
2026-02-08 19:20:46.121059: val_loss -0.9138 
2026-02-08 19:20:46.121105: Pseudo dice [np.float32(0.9579)] 
2026-02-08 19:20:46.121159: Epoch time: 66.41 s 
2026-02-08 19:20:46.121197: Yayy! New best EMA pseudo Dice: 0.9380000233650208 
2026-02-08 19:20:47.266099:  
2026-02-08 19:20:47.266363: Epoch 193 
2026-02-08 19:20:47.266463: Current learning rate: 0.00824 
2026-02-08 19:21:52.429672: train_loss -0.8639 
2026-02-08 19:21:52.430044: val_loss -0.8347 
2026-02-08 19:21:52.430085: Pseudo dice [np.float32(0.9124)] 
2026-02-08 19:21:52.430145: Epoch time: 65.16 s 
2026-02-08 19:21:53.129976:  
2026-02-08 19:21:53.130184: Epoch 194 
2026-02-08 19:21:53.130292: Current learning rate: 0.00824 
2026-02-08 19:23:00.701305: train_loss -0.8448 
2026-02-08 19:23:00.701729: val_loss -0.8141 
2026-02-08 19:23:00.701802: Pseudo dice [np.float32(0.8935)] 
2026-02-08 19:23:00.701861: Epoch time: 67.57 s 
2026-02-08 19:23:01.407006:  
2026-02-08 19:23:01.407282: Epoch 195 
2026-02-08 19:23:01.407382: Current learning rate: 0.00823 
2026-02-08 19:24:06.089108: train_loss -0.8781 
2026-02-08 19:24:06.089484: val_loss -0.8834 
2026-02-08 19:24:06.089607: Pseudo dice [np.float32(0.9324)] 
2026-02-08 19:24:06.089666: Epoch time: 64.68 s 
2026-02-08 19:24:06.798832:  
2026-02-08 19:24:06.799093: Epoch 196 
2026-02-08 19:24:06.799191: Current learning rate: 0.00822 
2026-02-08 19:25:14.349960: train_loss -0.8513 
2026-02-08 19:25:14.350416: val_loss -0.7735 
2026-02-08 19:25:14.350462: Pseudo dice [np.float32(0.8747)] 
2026-02-08 19:25:14.350518: Epoch time: 67.55 s 
2026-02-08 19:25:15.051975:  
2026-02-08 19:25:15.052220: Epoch 197 
2026-02-08 19:25:15.052328: Current learning rate: 0.00821 
2026-02-08 19:26:23.341088: train_loss -0.8636 
2026-02-08 19:26:23.341527: val_loss -0.8284 
2026-02-08 19:26:23.341568: Pseudo dice [np.float32(0.9043)] 
2026-02-08 19:26:23.341624: Epoch time: 68.29 s 
2026-02-08 19:26:24.054949:  
2026-02-08 19:26:24.055129: Epoch 198 
2026-02-08 19:26:24.055229: Current learning rate: 0.0082 
2026-02-08 19:27:30.581734: train_loss -0.8622 
2026-02-08 19:27:30.582054: val_loss -0.8973 
2026-02-08 19:27:30.582120: Pseudo dice [np.float32(0.9468)] 
2026-02-08 19:27:30.582211: Epoch time: 66.53 s 
2026-02-08 19:27:31.287530:  
2026-02-08 19:27:31.287810: Epoch 199 
2026-02-08 19:27:31.287932: Current learning rate: 0.00819 
2026-02-08 19:28:37.901939: train_loss -0.8783 
2026-02-08 19:28:37.902379: val_loss -0.8051 
2026-02-08 19:28:37.902483: Pseudo dice [np.float32(0.8991)] 
2026-02-08 19:28:37.902536: Epoch time: 66.62 s 
2026-02-08 19:28:39.060592:  
2026-02-08 19:28:39.060741: Epoch 200 
2026-02-08 19:28:39.060836: Current learning rate: 0.00818 
2026-02-08 19:29:44.168043: train_loss -0.8826 
2026-02-08 19:29:44.168414: val_loss -0.8618 
2026-02-08 19:29:44.168464: Pseudo dice [np.float32(0.9349)] 
2026-02-08 19:29:44.168518: Epoch time: 65.11 s 
2026-02-08 19:29:45.412617:  
2026-02-08 19:29:45.412898: Epoch 201 
2026-02-08 19:29:45.413119: Current learning rate: 0.00817 
