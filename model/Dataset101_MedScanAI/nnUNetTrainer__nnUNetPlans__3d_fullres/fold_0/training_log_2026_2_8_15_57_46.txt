
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2026-02-08 15:57:47.497512: Using torch.compile... 
2026-02-08 15:57:48.086497: do_dummy_2d_data_aug: False 
2026-02-08 15:57:48.087535: Using splits from existing split file: /Data2/cse_23103045/nnUNet_preprocessed/Dataset101_MedScanAI/splits_final.json 
2026-02-08 15:57:48.087725: The split file contains 5 splits. 
2026-02-08 15:57:48.087752: Desired fold for training: 0 
2026-02-08 15:57:48.087772: This split has 378 training and 95 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [417.0, 512.0, 512.0], 'spacing': [1.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset101_MedScanAI', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [103, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 103.05046844482422, 'median': 102.0, 'min': -1022.0, 'percentile_00_5': -57.0, 'percentile_99_5': 302.0, 'std': 73.22535705566406}}} 
 
2026-02-08 15:57:48.594065: Unable to plot network architecture: nnUNet_compile is enabled! 
2026-02-08 15:57:48.601210:  
2026-02-08 15:57:48.604837: Epoch 0 
2026-02-08 15:57:48.605037: Current learning rate: 0.01 
2026-02-08 15:59:18.990136: train_loss -0.0757 
2026-02-08 15:59:18.990618: val_loss -0.1367 
2026-02-08 15:59:18.990664: Pseudo dice [np.float32(0.4819)] 
2026-02-08 15:59:18.990718: Epoch time: 90.39 s 
2026-02-08 15:59:18.990754: Yayy! New best EMA pseudo Dice: 0.48190000653266907 
2026-02-08 15:59:20.012005:  
2026-02-08 15:59:20.012452: Epoch 1 
2026-02-08 15:59:20.012624: Current learning rate: 0.00999 
2026-02-08 16:00:12.128472: train_loss -0.2738 
2026-02-08 16:00:12.129019: val_loss -0.2224 
2026-02-08 16:00:12.129066: Pseudo dice [np.float32(0.5989)] 
2026-02-08 16:00:12.129129: Epoch time: 52.12 s 
2026-02-08 16:00:12.129167: Yayy! New best EMA pseudo Dice: 0.4936000108718872 
2026-02-08 16:00:13.237078:  
2026-02-08 16:00:13.237229: Epoch 2 
2026-02-08 16:00:13.237333: Current learning rate: 0.00998 
2026-02-08 16:01:05.327227: train_loss -0.374 
2026-02-08 16:01:05.327708: val_loss -0.3631 
2026-02-08 16:01:05.327755: Pseudo dice [np.float32(0.6111)] 
2026-02-08 16:01:05.327819: Epoch time: 52.09 s 
2026-02-08 16:01:05.327858: Yayy! New best EMA pseudo Dice: 0.505299985408783 
2026-02-08 16:01:06.443940:  
2026-02-08 16:01:06.444149: Epoch 3 
2026-02-08 16:01:06.444252: Current learning rate: 0.00997 
2026-02-08 16:01:58.527511: train_loss -0.488 
2026-02-08 16:01:58.528059: val_loss -0.5279 
2026-02-08 16:01:58.528109: Pseudo dice [np.float32(0.7291)] 
2026-02-08 16:01:58.528179: Epoch time: 52.08 s 
2026-02-08 16:01:58.528219: Yayy! New best EMA pseudo Dice: 0.5277000069618225 
2026-02-08 16:01:59.648308:  
2026-02-08 16:01:59.648659: Epoch 4 
2026-02-08 16:01:59.648750: Current learning rate: 0.00996 
2026-02-08 16:02:51.627037: train_loss -0.4919 
2026-02-08 16:02:51.627496: val_loss -0.5332 
2026-02-08 16:02:51.627602: Pseudo dice [np.float32(0.7437)] 
2026-02-08 16:02:51.627662: Epoch time: 51.98 s 
2026-02-08 16:02:51.627816: Yayy! New best EMA pseudo Dice: 0.5493000149726868 
2026-02-08 16:02:52.716611:  
2026-02-08 16:02:52.716792: Epoch 5 
2026-02-08 16:02:52.716887: Current learning rate: 0.00995 
2026-02-08 16:03:44.581751: train_loss -0.5818 
2026-02-08 16:03:44.582162: val_loss -0.5259 
2026-02-08 16:03:44.582302: Pseudo dice [np.float32(0.7462)] 
2026-02-08 16:03:44.582360: Epoch time: 51.87 s 
2026-02-08 16:03:44.582394: Yayy! New best EMA pseudo Dice: 0.5690000057220459 
2026-02-08 16:03:45.610529:  
2026-02-08 16:03:45.610746: Epoch 6 
2026-02-08 16:03:45.610832: Current learning rate: 0.00995 
2026-02-08 16:04:37.598518: train_loss -0.5851 
2026-02-08 16:04:37.598908: val_loss -0.5452 
2026-02-08 16:04:37.598999: Pseudo dice [np.float32(0.7547)] 
2026-02-08 16:04:37.599057: Epoch time: 51.99 s 
2026-02-08 16:04:37.599098: Yayy! New best EMA pseudo Dice: 0.5875999927520752 
2026-02-08 16:04:38.653711:  
2026-02-08 16:04:38.653868: Epoch 7 
2026-02-08 16:04:38.653962: Current learning rate: 0.00994 
2026-02-08 16:05:35.951356: train_loss -0.6036 
2026-02-08 16:05:35.951794: val_loss -0.6373 
2026-02-08 16:05:35.951843: Pseudo dice [np.float32(0.7968)] 
2026-02-08 16:05:35.951901: Epoch time: 57.3 s 
2026-02-08 16:05:35.951938: Yayy! New best EMA pseudo Dice: 0.6085000038146973 
2026-02-08 16:05:37.010906:  
2026-02-08 16:05:37.011207: Epoch 8 
2026-02-08 16:05:37.011329: Current learning rate: 0.00993 
2026-02-08 16:06:49.670570: train_loss -0.6418 
2026-02-08 16:06:49.670979: val_loss -0.7421 
2026-02-08 16:06:49.671048: Pseudo dice [np.float32(0.8526)] 
2026-02-08 16:06:49.671108: Epoch time: 72.66 s 
2026-02-08 16:06:49.671145: Yayy! New best EMA pseudo Dice: 0.6328999996185303 
2026-02-08 16:06:50.740237:  
2026-02-08 16:06:50.740563: Epoch 9 
2026-02-08 16:06:50.740681: Current learning rate: 0.00992 
2026-02-08 16:08:02.666706: train_loss -0.6932 
2026-02-08 16:08:02.667116: val_loss -0.5577 
2026-02-08 16:08:02.667158: Pseudo dice [np.float32(0.7473)] 
2026-02-08 16:08:02.667206: Epoch time: 71.93 s 
2026-02-08 16:08:02.667240: Yayy! New best EMA pseudo Dice: 0.6442999839782715 
2026-02-08 16:08:03.727464:  
2026-02-08 16:08:03.727786: Epoch 10 
2026-02-08 16:08:03.727929: Current learning rate: 0.00991 
2026-02-08 16:09:17.661722: train_loss -0.6191 
2026-02-08 16:09:17.662194: val_loss -0.6963 
2026-02-08 16:09:17.662241: Pseudo dice [np.float32(0.8286)] 
2026-02-08 16:09:17.662304: Epoch time: 73.94 s 
2026-02-08 16:09:17.662345: Yayy! New best EMA pseudo Dice: 0.6628000140190125 
2026-02-08 16:09:18.714844:  
2026-02-08 16:09:18.715047: Epoch 11 
2026-02-08 16:09:18.715136: Current learning rate: 0.0099 
2026-02-08 16:10:29.609600: train_loss -0.6496 
2026-02-08 16:10:29.610020: val_loss -0.7419 
2026-02-08 16:10:29.610083: Pseudo dice [np.float32(0.8507)] 
2026-02-08 16:10:29.610169: Epoch time: 70.9 s 
2026-02-08 16:10:29.610248: Yayy! New best EMA pseudo Dice: 0.6815000176429749 
2026-02-08 16:10:31.472731:  
2026-02-08 16:10:31.473161: Epoch 12 
2026-02-08 16:10:31.473329: Current learning rate: 0.00989 
2026-02-08 16:11:42.736814: train_loss -0.7398 
2026-02-08 16:11:42.737237: val_loss -0.6887 
2026-02-08 16:11:42.737294: Pseudo dice [np.float32(0.8406)] 
2026-02-08 16:11:42.737355: Epoch time: 71.27 s 
2026-02-08 16:11:42.737390: Yayy! New best EMA pseudo Dice: 0.6974999904632568 
2026-02-08 16:11:43.859369:  
2026-02-08 16:11:43.859516: Epoch 13 
2026-02-08 16:11:43.859641: Current learning rate: 0.00988 
2026-02-08 16:12:55.512880: train_loss -0.7406 
2026-02-08 16:12:55.513290: val_loss -0.7527 
2026-02-08 16:12:55.513363: Pseudo dice [np.float32(0.8613)] 
2026-02-08 16:12:55.513448: Epoch time: 71.65 s 
2026-02-08 16:12:55.513487: Yayy! New best EMA pseudo Dice: 0.7138000130653381 
2026-02-08 16:12:56.616017:  
2026-02-08 16:12:56.616228: Epoch 14 
2026-02-08 16:12:56.616320: Current learning rate: 0.00987 
2026-02-08 16:14:07.451387: train_loss -0.7654 
2026-02-08 16:14:07.451810: val_loss -0.6857 
2026-02-08 16:14:07.451855: Pseudo dice [np.float32(0.8273)] 
2026-02-08 16:14:07.451915: Epoch time: 70.84 s 
2026-02-08 16:14:07.451952: Yayy! New best EMA pseudo Dice: 0.7251999974250793 
2026-02-08 16:14:08.527988:  
2026-02-08 16:14:08.528103: Epoch 15 
2026-02-08 16:14:08.528192: Current learning rate: 0.00986 
2026-02-08 16:15:22.520015: train_loss -0.7195 
2026-02-08 16:15:22.520613: val_loss -0.7558 
2026-02-08 16:15:22.520694: Pseudo dice [np.float32(0.8704)] 
2026-02-08 16:15:22.520812: Epoch time: 73.99 s 
2026-02-08 16:15:22.520852: Yayy! New best EMA pseudo Dice: 0.7397000193595886 
2026-02-08 16:15:23.620403:  
2026-02-08 16:15:23.620568: Epoch 16 
2026-02-08 16:15:23.620656: Current learning rate: 0.00986 
2026-02-08 16:16:34.277947: train_loss -0.7168 
2026-02-08 16:16:34.278329: val_loss -0.7473 
2026-02-08 16:16:34.278411: Pseudo dice [np.float32(0.8637)] 
2026-02-08 16:16:34.278469: Epoch time: 70.66 s 
2026-02-08 16:16:34.278505: Yayy! New best EMA pseudo Dice: 0.7520999908447266 
2026-02-08 16:16:35.359395:  
2026-02-08 16:16:35.359568: Epoch 17 
2026-02-08 16:16:35.359659: Current learning rate: 0.00985 
2026-02-08 16:17:47.639154: train_loss -0.7446 
2026-02-08 16:17:47.639606: val_loss -0.7999 
2026-02-08 16:17:47.639654: Pseudo dice [np.float32(0.9004)] 
2026-02-08 16:17:47.639710: Epoch time: 72.28 s 
2026-02-08 16:17:47.639747: Yayy! New best EMA pseudo Dice: 0.7669000029563904 
2026-02-08 16:17:48.715261:  
2026-02-08 16:17:48.715378: Epoch 18 
2026-02-08 16:17:48.715467: Current learning rate: 0.00984 
2026-02-08 16:19:01.429880: train_loss -0.7601 
2026-02-08 16:19:01.430295: val_loss -0.648 
2026-02-08 16:19:01.430346: Pseudo dice [np.float32(0.8053)] 
2026-02-08 16:19:01.430405: Epoch time: 72.72 s 
2026-02-08 16:19:01.430453: Yayy! New best EMA pseudo Dice: 0.770799994468689 
2026-02-08 16:19:02.506662:  
2026-02-08 16:19:02.507010: Epoch 19 
2026-02-08 16:19:02.507103: Current learning rate: 0.00983 
2026-02-08 16:20:14.703748: train_loss -0.7014 
2026-02-08 16:20:14.704158: val_loss -0.728 
2026-02-08 16:20:14.704207: Pseudo dice [np.float32(0.8676)] 
2026-02-08 16:20:14.704259: Epoch time: 72.2 s 
2026-02-08 16:20:14.704306: Yayy! New best EMA pseudo Dice: 0.7803999781608582 
2026-02-08 16:20:15.793852:  
2026-02-08 16:20:15.794019: Epoch 20 
2026-02-08 16:20:15.794110: Current learning rate: 0.00982 
2026-02-08 16:21:27.338948: train_loss -0.723 
2026-02-08 16:21:27.339395: val_loss -0.7673 
2026-02-08 16:21:27.339441: Pseudo dice [np.float32(0.891)] 
2026-02-08 16:21:27.339499: Epoch time: 71.55 s 
2026-02-08 16:21:27.339537: Yayy! New best EMA pseudo Dice: 0.7914999723434448 
2026-02-08 16:21:28.430142:  
2026-02-08 16:21:28.430408: Epoch 21 
2026-02-08 16:21:28.430500: Current learning rate: 0.00981 
2026-02-08 16:22:40.064750: train_loss -0.7345 
2026-02-08 16:22:40.065178: val_loss -0.6666 
2026-02-08 16:22:40.065226: Pseudo dice [np.float32(0.8193)] 
2026-02-08 16:22:40.065292: Epoch time: 71.64 s 
2026-02-08 16:22:40.065331: Yayy! New best EMA pseudo Dice: 0.7943000197410583 
2026-02-08 16:22:41.128505:  
2026-02-08 16:22:41.128762: Epoch 22 
2026-02-08 16:22:41.128901: Current learning rate: 0.0098 
2026-02-08 16:23:53.643679: train_loss -0.6823 
2026-02-08 16:23:53.644128: val_loss -0.7812 
2026-02-08 16:23:53.644219: Pseudo dice [np.float32(0.8866)] 
2026-02-08 16:23:53.644289: Epoch time: 72.52 s 
2026-02-08 16:23:53.644328: Yayy! New best EMA pseudo Dice: 0.8034999966621399 
2026-02-08 16:23:54.707061:  
2026-02-08 16:23:54.707302: Epoch 23 
2026-02-08 16:23:54.707399: Current learning rate: 0.00979 
2026-02-08 16:25:05.567613: train_loss -0.777 
2026-02-08 16:25:05.568084: val_loss -0.7335 
2026-02-08 16:25:05.568164: Pseudo dice [np.float32(0.8526)] 
2026-02-08 16:25:05.568227: Epoch time: 70.86 s 
2026-02-08 16:25:05.568275: Yayy! New best EMA pseudo Dice: 0.8083999752998352 
2026-02-08 16:25:06.672426:  
2026-02-08 16:25:06.672536: Epoch 24 
2026-02-08 16:25:06.672621: Current learning rate: 0.00978 
2026-02-08 16:26:18.344179: train_loss -0.7834 
2026-02-08 16:26:18.344606: val_loss -0.7784 
2026-02-08 16:26:18.344708: Pseudo dice [np.float32(0.8787)] 
2026-02-08 16:26:18.344775: Epoch time: 71.67 s 
2026-02-08 16:26:18.344813: Yayy! New best EMA pseudo Dice: 0.815500020980835 
2026-02-08 16:26:19.396538:  
2026-02-08 16:26:19.396721: Epoch 25 
2026-02-08 16:26:19.396888: Current learning rate: 0.00977 
2026-02-08 16:27:31.421131: train_loss -0.7508 
2026-02-08 16:27:31.421643: val_loss -0.8024 
2026-02-08 16:27:31.421736: Pseudo dice [np.float32(0.8756)] 
2026-02-08 16:27:31.421798: Epoch time: 72.03 s 
2026-02-08 16:27:31.421834: Yayy! New best EMA pseudo Dice: 0.8215000033378601 
2026-02-08 16:27:33.111080:  
2026-02-08 16:27:33.111234: Epoch 26 
2026-02-08 16:27:33.111331: Current learning rate: 0.00977 
2026-02-08 16:28:44.583921: train_loss -0.7646 
2026-02-08 16:28:44.584414: val_loss -0.8402 
2026-02-08 16:28:44.584466: Pseudo dice [np.float32(0.9154)] 
2026-02-08 16:28:44.584526: Epoch time: 71.47 s 
2026-02-08 16:28:44.584561: Yayy! New best EMA pseudo Dice: 0.8309000134468079 
2026-02-08 16:28:45.641741:  
2026-02-08 16:28:45.641946: Epoch 27 
2026-02-08 16:28:45.642113: Current learning rate: 0.00976 
2026-02-08 16:29:59.233797: train_loss -0.8048 
2026-02-08 16:29:59.234256: val_loss -0.7946 
2026-02-08 16:29:59.234317: Pseudo dice [np.float32(0.887)] 
2026-02-08 16:29:59.234376: Epoch time: 73.59 s 
2026-02-08 16:29:59.234412: Yayy! New best EMA pseudo Dice: 0.8364999890327454 
2026-02-08 16:30:00.340598:  
2026-02-08 16:30:00.340728: Epoch 28 
2026-02-08 16:30:00.340854: Current learning rate: 0.00975 
2026-02-08 16:31:17.558371: train_loss -0.8003 
2026-02-08 16:31:17.558782: val_loss -0.7965 
2026-02-08 16:31:17.558826: Pseudo dice [np.float32(0.8801)] 
2026-02-08 16:31:17.558878: Epoch time: 77.22 s 
2026-02-08 16:31:17.558913: Yayy! New best EMA pseudo Dice: 0.8407999873161316 
2026-02-08 16:31:18.629786:  
2026-02-08 16:31:18.629961: Epoch 29 
2026-02-08 16:31:18.630049: Current learning rate: 0.00974 
2026-02-08 16:32:29.905113: train_loss -0.7814 
2026-02-08 16:32:29.905598: val_loss -0.8313 
2026-02-08 16:32:29.905649: Pseudo dice [np.float32(0.9191)] 
2026-02-08 16:32:29.905710: Epoch time: 71.28 s 
2026-02-08 16:32:29.905749: Yayy! New best EMA pseudo Dice: 0.8486999869346619 
2026-02-08 16:32:30.971868:  
2026-02-08 16:32:30.972049: Epoch 30 
2026-02-08 16:32:30.972172: Current learning rate: 0.00973 
2026-02-08 16:33:43.141170: train_loss -0.793 
2026-02-08 16:33:43.141659: val_loss -0.7252 
2026-02-08 16:33:43.141703: Pseudo dice [np.float32(0.8337)] 
2026-02-08 16:33:43.141762: Epoch time: 72.17 s 
2026-02-08 16:33:43.845721:  
2026-02-08 16:33:43.845986: Epoch 31 
2026-02-08 16:33:43.846108: Current learning rate: 0.00972 
2026-02-08 16:34:55.087229: train_loss -0.7977 
2026-02-08 16:34:55.087678: val_loss -0.8611 
2026-02-08 16:34:55.087721: Pseudo dice [np.float32(0.9282)] 
2026-02-08 16:34:55.087779: Epoch time: 71.24 s 
2026-02-08 16:34:55.087816: Yayy! New best EMA pseudo Dice: 0.8553000092506409 
2026-02-08 16:34:56.163018:  
2026-02-08 16:34:56.163208: Epoch 32 
2026-02-08 16:34:56.163304: Current learning rate: 0.00971 
2026-02-08 16:36:09.603461: train_loss -0.7673 
2026-02-08 16:36:09.603931: val_loss -0.8126 
2026-02-08 16:36:09.603979: Pseudo dice [np.float32(0.8958)] 
2026-02-08 16:36:09.604046: Epoch time: 73.44 s 
2026-02-08 16:36:09.604082: Yayy! New best EMA pseudo Dice: 0.8593000173568726 
2026-02-08 16:36:10.700604:  
2026-02-08 16:36:10.700715: Epoch 33 
2026-02-08 16:36:10.700848: Current learning rate: 0.0097 
2026-02-08 16:37:21.677447: train_loss -0.7845 
2026-02-08 16:37:21.677853: val_loss -0.6822 
2026-02-08 16:37:21.677970: Pseudo dice [np.float32(0.8303)] 
2026-02-08 16:37:21.678061: Epoch time: 70.98 s 
2026-02-08 16:37:22.364221:  
2026-02-08 16:37:22.364476: Epoch 34 
2026-02-08 16:37:22.364566: Current learning rate: 0.00969 
2026-02-08 16:38:34.384946: train_loss -0.8099 
2026-02-08 16:38:34.385333: val_loss -0.7874 
2026-02-08 16:38:34.385443: Pseudo dice [np.float32(0.8868)] 
2026-02-08 16:38:34.385509: Epoch time: 72.02 s 
2026-02-08 16:38:34.385545: Yayy! New best EMA pseudo Dice: 0.859499990940094 
2026-02-08 16:38:35.501661:  
2026-02-08 16:38:35.501822: Epoch 35 
2026-02-08 16:38:35.501913: Current learning rate: 0.00968 
2026-02-08 16:39:47.195765: train_loss -0.8023 
2026-02-08 16:39:47.196152: val_loss -0.775 
2026-02-08 16:39:47.196198: Pseudo dice [np.float32(0.8982)] 
2026-02-08 16:39:47.196255: Epoch time: 71.69 s 
2026-02-08 16:39:47.196300: Yayy! New best EMA pseudo Dice: 0.8633000254631042 
2026-02-08 16:39:48.244169:  
2026-02-08 16:39:48.244343: Epoch 36 
2026-02-08 16:39:48.244435: Current learning rate: 0.00968 
2026-02-08 16:40:58.571930: train_loss -0.8008 
2026-02-08 16:40:58.572390: val_loss -0.8523 
2026-02-08 16:40:58.572505: Pseudo dice [np.float32(0.9289)] 
2026-02-08 16:40:58.572568: Epoch time: 70.33 s 
2026-02-08 16:40:58.572605: Yayy! New best EMA pseudo Dice: 0.8698999881744385 
2026-02-08 16:40:59.665055:  
2026-02-08 16:40:59.665184: Epoch 37 
2026-02-08 16:40:59.665343: Current learning rate: 0.00967 
2026-02-08 16:42:09.022212: train_loss -0.8077 
2026-02-08 16:42:09.022681: val_loss -0.8433 
2026-02-08 16:42:09.022817: Pseudo dice [np.float32(0.9194)] 
2026-02-08 16:42:09.022880: Epoch time: 69.36 s 
2026-02-08 16:42:09.022918: Yayy! New best EMA pseudo Dice: 0.8748000264167786 
2026-02-08 16:42:10.091729:  
2026-02-08 16:42:10.091938: Epoch 38 
2026-02-08 16:42:10.092197: Current learning rate: 0.00966 
2026-02-08 16:43:21.268629: train_loss -0.792 
2026-02-08 16:43:21.268958: val_loss -0.8418 
2026-02-08 16:43:21.269031: Pseudo dice [np.float32(0.9268)] 
2026-02-08 16:43:21.269124: Epoch time: 71.18 s 
2026-02-08 16:43:21.269196: Yayy! New best EMA pseudo Dice: 0.8799999952316284 
2026-02-08 16:43:22.892336:  
2026-02-08 16:43:22.892630: Epoch 39 
2026-02-08 16:43:22.892729: Current learning rate: 0.00965 
2026-02-08 16:44:33.902409: train_loss -0.7973 
2026-02-08 16:44:33.902837: val_loss -0.8522 
2026-02-08 16:44:33.902889: Pseudo dice [np.float32(0.9278)] 
2026-02-08 16:44:33.902953: Epoch time: 71.01 s 
2026-02-08 16:44:33.902989: Yayy! New best EMA pseudo Dice: 0.8848000168800354 
2026-02-08 16:44:34.970250:  
2026-02-08 16:44:34.970444: Epoch 40 
2026-02-08 16:44:34.970533: Current learning rate: 0.00964 
2026-02-08 16:45:45.458151: train_loss -0.868 
2026-02-08 16:45:45.458606: val_loss -0.8282 
2026-02-08 16:45:45.458664: Pseudo dice [np.float32(0.92)] 
2026-02-08 16:45:45.458725: Epoch time: 70.49 s 
2026-02-08 16:45:45.458761: Yayy! New best EMA pseudo Dice: 0.8883000016212463 
2026-02-08 16:45:46.596766:  
2026-02-08 16:45:46.596975: Epoch 41 
2026-02-08 16:45:46.597123: Current learning rate: 0.00963 
2026-02-08 16:46:54.165127: train_loss -0.8047 
2026-02-08 16:46:54.165621: val_loss -0.8471 
2026-02-08 16:46:54.165666: Pseudo dice [np.float32(0.9244)] 
2026-02-08 16:46:54.165728: Epoch time: 67.57 s 
2026-02-08 16:46:54.165764: Yayy! New best EMA pseudo Dice: 0.8919000029563904 
2026-02-08 16:46:55.234197:  
2026-02-08 16:46:55.234472: Epoch 42 
2026-02-08 16:46:55.234638: Current learning rate: 0.00962 
2026-02-08 16:48:04.774806: train_loss -0.8166 
2026-02-08 16:48:04.775144: val_loss -0.8289 
2026-02-08 16:48:04.775187: Pseudo dice [np.float32(0.9075)] 
2026-02-08 16:48:04.775247: Epoch time: 69.54 s 
2026-02-08 16:48:04.775290: Yayy! New best EMA pseudo Dice: 0.8934999704360962 
2026-02-08 16:48:05.843820:  
2026-02-08 16:48:05.843985: Epoch 43 
2026-02-08 16:48:05.844076: Current learning rate: 0.00961 
2026-02-08 16:49:16.508681: train_loss -0.7985 
2026-02-08 16:49:16.509204: val_loss -0.8011 
2026-02-08 16:49:16.509250: Pseudo dice [np.float32(0.8756)] 
2026-02-08 16:49:16.509343: Epoch time: 70.67 s 
2026-02-08 16:49:17.182151:  
2026-02-08 16:49:17.182348: Epoch 44 
2026-02-08 16:49:17.182446: Current learning rate: 0.0096 
2026-02-08 16:50:27.228610: train_loss -0.8156 
2026-02-08 16:50:27.229127: val_loss -0.8768 
2026-02-08 16:50:27.229178: Pseudo dice [np.float32(0.9366)] 
2026-02-08 16:50:27.229249: Epoch time: 70.05 s 
2026-02-08 16:50:27.229298: Yayy! New best EMA pseudo Dice: 0.8962000012397766 
2026-02-08 16:50:28.315563:  
2026-02-08 16:50:28.315914: Epoch 45 
2026-02-08 16:50:28.316004: Current learning rate: 0.00959 
2026-02-08 16:51:40.964958: train_loss -0.8581 
2026-02-08 16:51:40.965386: val_loss -0.7987 
2026-02-08 16:51:40.965436: Pseudo dice [np.float32(0.8907)] 
2026-02-08 16:51:40.965496: Epoch time: 72.65 s 
2026-02-08 16:51:41.639770:  
2026-02-08 16:51:41.639935: Epoch 46 
2026-02-08 16:51:41.640024: Current learning rate: 0.00959 
2026-02-08 16:52:53.573379: train_loss -0.8448 
2026-02-08 16:52:53.573900: val_loss -0.8149 
2026-02-08 16:52:53.573947: Pseudo dice [np.float32(0.9179)] 
2026-02-08 16:52:53.574012: Epoch time: 71.93 s 
2026-02-08 16:52:53.574049: Yayy! New best EMA pseudo Dice: 0.8978999853134155 
2026-02-08 16:52:54.659510:  
2026-02-08 16:52:54.659842: Epoch 47 
2026-02-08 16:52:54.660013: Current learning rate: 0.00958 
2026-02-08 16:54:06.027073: train_loss -0.8312 
2026-02-08 16:54:06.027509: val_loss -0.85 
2026-02-08 16:54:06.027570: Pseudo dice [np.float32(0.9277)] 
2026-02-08 16:54:06.027634: Epoch time: 71.37 s 
2026-02-08 16:54:06.027679: Yayy! New best EMA pseudo Dice: 0.9007999897003174 
2026-02-08 16:54:07.127058:  
2026-02-08 16:54:07.127281: Epoch 48 
2026-02-08 16:54:07.127381: Current learning rate: 0.00957 
2026-02-08 16:55:17.703245: train_loss -0.8462 
2026-02-08 16:55:17.703745: val_loss -0.8536 
2026-02-08 16:55:17.703838: Pseudo dice [np.float32(0.9322)] 
2026-02-08 16:55:17.703916: Epoch time: 70.58 s 
2026-02-08 16:55:17.703961: Yayy! New best EMA pseudo Dice: 0.9039999842643738 
2026-02-08 16:55:18.785290:  
2026-02-08 16:55:18.785640: Epoch 49 
2026-02-08 16:55:18.785732: Current learning rate: 0.00956 
2026-02-08 16:56:28.977357: train_loss -0.8633 
2026-02-08 16:56:28.978145: val_loss -0.8453 
2026-02-08 16:56:28.978196: Pseudo dice [np.float32(0.922)] 
2026-02-08 16:56:28.978323: Epoch time: 70.19 s 
2026-02-08 16:56:29.357603: Yayy! New best EMA pseudo Dice: 0.9057999849319458 
2026-02-08 16:56:30.409194:  
2026-02-08 16:56:30.409608: Epoch 50 
2026-02-08 16:56:30.409708: Current learning rate: 0.00955 
2026-02-08 16:57:41.483785: train_loss -0.8513 
2026-02-08 16:57:41.484164: val_loss -0.8055 
2026-02-08 16:57:41.484207: Pseudo dice [np.float32(0.8784)] 
2026-02-08 16:57:41.484284: Epoch time: 71.08 s 
2026-02-08 16:57:42.161280:  
2026-02-08 16:57:42.161542: Epoch 51 
2026-02-08 16:57:42.161645: Current learning rate: 0.00954 
2026-02-08 16:58:52.973575: train_loss -0.8058 
2026-02-08 16:58:52.974134: val_loss -0.8663 
2026-02-08 16:58:52.974223: Pseudo dice [np.float32(0.9294)] 
2026-02-08 16:58:52.974343: Epoch time: 70.81 s 
2026-02-08 16:58:53.677480:  
2026-02-08 16:58:53.677718: Epoch 52 
2026-02-08 16:58:53.677823: Current learning rate: 0.00953 
2026-02-08 17:00:04.271549: train_loss -0.806 
2026-02-08 17:00:04.272058: val_loss -0.8744 
2026-02-08 17:00:04.272106: Pseudo dice [np.float32(0.9367)] 
2026-02-08 17:00:04.272172: Epoch time: 70.6 s 
2026-02-08 17:00:04.272210: Yayy! New best EMA pseudo Dice: 0.9088000059127808 
2026-02-08 17:00:06.137951:  
2026-02-08 17:00:06.138280: Epoch 53 
2026-02-08 17:00:06.138391: Current learning rate: 0.00952 
2026-02-08 17:01:16.778442: train_loss -0.8603 
2026-02-08 17:01:16.778828: val_loss -0.8613 
2026-02-08 17:01:16.778907: Pseudo dice [np.float32(0.9291)] 
2026-02-08 17:01:16.778970: Epoch time: 70.64 s 
2026-02-08 17:01:16.779006: Yayy! New best EMA pseudo Dice: 0.9107999801635742 
2026-02-08 17:01:18.028529:  
2026-02-08 17:01:18.028684: Epoch 54 
2026-02-08 17:01:18.028780: Current learning rate: 0.00951 
2026-02-08 17:02:28.702957: train_loss -0.8848 
2026-02-08 17:02:28.703445: val_loss -0.8965 
2026-02-08 17:02:28.703496: Pseudo dice [np.float32(0.948)] 
2026-02-08 17:02:28.703563: Epoch time: 70.68 s 
2026-02-08 17:02:28.703599: Yayy! New best EMA pseudo Dice: 0.9144999980926514 
2026-02-08 17:02:29.773121:  
2026-02-08 17:02:29.773426: Epoch 55 
2026-02-08 17:02:29.773532: Current learning rate: 0.0095 
2026-02-08 17:03:40.580939: train_loss -0.8802 
2026-02-08 17:03:40.581432: val_loss -0.8636 
2026-02-08 17:03:40.581474: Pseudo dice [np.float32(0.9347)] 
2026-02-08 17:03:40.581541: Epoch time: 70.81 s 
2026-02-08 17:03:40.581581: Yayy! New best EMA pseudo Dice: 0.9164999723434448 
2026-02-08 17:03:41.683662:  
2026-02-08 17:03:41.684059: Epoch 56 
2026-02-08 17:03:41.684162: Current learning rate: 0.00949 
2026-02-08 17:04:52.697575: train_loss -0.8288 
2026-02-08 17:04:52.698003: val_loss -0.6476 
2026-02-08 17:04:52.698050: Pseudo dice [np.float32(0.8054)] 
2026-02-08 17:04:52.698116: Epoch time: 71.01 s 
2026-02-08 17:04:53.370764:  
2026-02-08 17:04:53.371021: Epoch 57 
2026-02-08 17:04:53.371120: Current learning rate: 0.00949 
2026-02-08 17:06:00.839205: train_loss -0.7681 
2026-02-08 17:06:00.839683: val_loss -0.7244 
2026-02-08 17:06:00.839730: Pseudo dice [np.float32(0.8388)] 
2026-02-08 17:06:00.839794: Epoch time: 67.47 s 
2026-02-08 17:06:01.511053:  
2026-02-08 17:06:01.511277: Epoch 58 
2026-02-08 17:06:01.511379: Current learning rate: 0.00948 
2026-02-08 17:07:11.883850: train_loss -0.801 
2026-02-08 17:07:11.884403: val_loss -0.8704 
2026-02-08 17:07:11.884455: Pseudo dice [np.float32(0.9334)] 
2026-02-08 17:07:11.884518: Epoch time: 70.37 s 
2026-02-08 17:07:12.575591:  
2026-02-08 17:07:12.575835: Epoch 59 
2026-02-08 17:07:12.575994: Current learning rate: 0.00947 
2026-02-08 17:08:24.304579: train_loss -0.8217 
2026-02-08 17:08:24.305022: val_loss -0.8346 
2026-02-08 17:08:24.305068: Pseudo dice [np.float32(0.925)] 
2026-02-08 17:08:24.305130: Epoch time: 71.73 s 
2026-02-08 17:08:24.984131:  
2026-02-08 17:08:24.984354: Epoch 60 
2026-02-08 17:08:24.984477: Current learning rate: 0.00946 
2026-02-08 17:09:36.126728: train_loss -0.8351 
2026-02-08 17:09:36.127159: val_loss -0.8591 
2026-02-08 17:09:36.127253: Pseudo dice [np.float32(0.9222)] 
2026-02-08 17:09:36.127329: Epoch time: 71.14 s 
2026-02-08 17:09:36.813725:  
2026-02-08 17:09:36.813930: Epoch 61 
2026-02-08 17:09:36.814027: Current learning rate: 0.00945 
2026-02-08 17:10:45.614085: train_loss -0.8516 
2026-02-08 17:10:45.614517: val_loss -0.9016 
2026-02-08 17:10:45.614566: Pseudo dice [np.float32(0.9496)] 
2026-02-08 17:10:45.614626: Epoch time: 68.8 s 
2026-02-08 17:10:46.281921:  
2026-02-08 17:10:46.282055: Epoch 62 
2026-02-08 17:10:46.282153: Current learning rate: 0.00944 
2026-02-08 17:11:56.730123: train_loss -0.849 
2026-02-08 17:11:56.730511: val_loss -0.8801 
2026-02-08 17:11:56.730585: Pseudo dice [np.float32(0.9386)] 
2026-02-08 17:11:56.730674: Epoch time: 70.45 s 
2026-02-08 17:11:57.405856:  
2026-02-08 17:11:57.406188: Epoch 63 
2026-02-08 17:11:57.406295: Current learning rate: 0.00943 
2026-02-08 17:13:07.461816: train_loss -0.8541 
2026-02-08 17:13:07.462277: val_loss -0.8871 
2026-02-08 17:13:07.462325: Pseudo dice [np.float32(0.9408)] 
2026-02-08 17:13:07.462386: Epoch time: 70.06 s 
2026-02-08 17:13:08.138631:  
2026-02-08 17:13:08.139003: Epoch 64 
2026-02-08 17:13:08.139107: Current learning rate: 0.00942 
2026-02-08 17:14:17.227400: train_loss -0.8693 
2026-02-08 17:14:17.227812: val_loss -0.8739 
2026-02-08 17:14:17.227883: Pseudo dice [np.float32(0.9298)] 
2026-02-08 17:14:17.227940: Epoch time: 69.09 s 
2026-02-08 17:14:17.227977: Yayy! New best EMA pseudo Dice: 0.9175000190734863 
2026-02-08 17:14:18.302808:  
2026-02-08 17:14:18.303016: Epoch 65 
2026-02-08 17:14:18.303125: Current learning rate: 0.00941 
2026-02-08 17:15:29.163009: train_loss -0.8796 
2026-02-08 17:15:29.163433: val_loss -0.7799 
2026-02-08 17:15:29.163481: Pseudo dice [np.float32(0.8816)] 
2026-02-08 17:15:29.163543: Epoch time: 70.86 s 
2026-02-08 17:15:29.836536:  
2026-02-08 17:15:29.836784: Epoch 66 
2026-02-08 17:15:29.836945: Current learning rate: 0.0094 
2026-02-08 17:16:42.372597: train_loss -0.8378 
2026-02-08 17:16:42.372868: val_loss -0.8627 
2026-02-08 17:16:42.372916: Pseudo dice [np.float32(0.9091)] 
2026-02-08 17:16:42.372981: Epoch time: 72.54 s 
2026-02-08 17:16:43.050150:  
2026-02-08 17:16:43.050404: Epoch 67 
2026-02-08 17:16:43.050515: Current learning rate: 0.00939 
2026-02-08 17:17:53.330793: train_loss -0.8477 
2026-02-08 17:17:53.331161: val_loss -0.8272 
2026-02-08 17:17:53.331208: Pseudo dice [np.float32(0.8874)] 
2026-02-08 17:17:53.331281: Epoch time: 70.28 s 
2026-02-08 17:17:54.830432:  
2026-02-08 17:17:54.830727: Epoch 68 
2026-02-08 17:17:54.830874: Current learning rate: 0.00939 
2026-02-08 17:19:07.681935: train_loss -0.8397 
2026-02-08 17:19:07.682396: val_loss -0.8843 
2026-02-08 17:19:07.682445: Pseudo dice [np.float32(0.9436)] 
2026-02-08 17:19:07.682509: Epoch time: 72.85 s 
2026-02-08 17:19:08.359374:  
2026-02-08 17:19:08.359649: Epoch 69 
2026-02-08 17:19:08.359890: Current learning rate: 0.00938 
2026-02-08 17:20:19.483650: train_loss -0.8313 
2026-02-08 17:20:19.484071: val_loss -0.7617 
2026-02-08 17:20:19.484214: Pseudo dice [np.float32(0.874)] 
2026-02-08 17:20:19.484292: Epoch time: 71.13 s 
2026-02-08 17:20:20.161488:  
2026-02-08 17:20:20.161841: Epoch 70 
2026-02-08 17:20:20.161963: Current learning rate: 0.00937 
2026-02-08 17:21:28.516580: train_loss -0.8546 
2026-02-08 17:21:28.517026: val_loss -0.8835 
2026-02-08 17:21:28.517071: Pseudo dice [np.float32(0.9426)] 
2026-02-08 17:21:28.517135: Epoch time: 68.36 s 
2026-02-08 17:21:29.195804:  
2026-02-08 17:21:29.196034: Epoch 71 
2026-02-08 17:21:29.196137: Current learning rate: 0.00936 
2026-02-08 17:22:39.142435: train_loss -0.8292 
2026-02-08 17:22:39.149882: val_loss -0.7663 
2026-02-08 17:22:39.149974: Pseudo dice [np.float32(0.8574)] 
2026-02-08 17:22:39.150076: Epoch time: 69.95 s 
2026-02-08 17:22:39.826544:  
2026-02-08 17:22:39.826845: Epoch 72 
2026-02-08 17:22:39.827043: Current learning rate: 0.00935 
2026-02-08 17:23:49.300432: train_loss -0.8085 
2026-02-08 17:23:49.300762: val_loss -0.8623 
2026-02-08 17:23:49.300809: Pseudo dice [np.float32(0.9247)] 
2026-02-08 17:23:49.300900: Epoch time: 69.47 s 
2026-02-08 17:23:49.990059:  
2026-02-08 17:23:49.990247: Epoch 73 
2026-02-08 17:23:49.990352: Current learning rate: 0.00934 
2026-02-08 17:24:58.168848: train_loss -0.8531 
2026-02-08 17:24:58.169256: val_loss -0.8586 
2026-02-08 17:24:58.169313: Pseudo dice [np.float32(0.9386)] 
2026-02-08 17:24:58.169372: Epoch time: 68.18 s 
2026-02-08 17:24:58.864289:  
2026-02-08 17:24:58.864563: Epoch 74 
2026-02-08 17:24:58.864666: Current learning rate: 0.00933 
2026-02-08 17:26:12.115023: train_loss -0.825 
2026-02-08 17:26:12.115420: val_loss -0.8071 
2026-02-08 17:26:12.115466: Pseudo dice [np.float32(0.8977)] 
2026-02-08 17:26:12.115523: Epoch time: 73.25 s 
2026-02-08 17:26:12.797120:  
2026-02-08 17:26:12.797354: Epoch 75 
2026-02-08 17:26:12.797454: Current learning rate: 0.00932 
2026-02-08 17:27:21.743074: train_loss -0.8293 
2026-02-08 17:27:21.743582: val_loss -0.8003 
2026-02-08 17:27:21.743645: Pseudo dice [np.float32(0.8968)] 
2026-02-08 17:27:21.743711: Epoch time: 68.95 s 
2026-02-08 17:27:22.430554:  
2026-02-08 17:27:22.430721: Epoch 76 
2026-02-08 17:27:22.430820: Current learning rate: 0.00931 
2026-02-08 17:28:31.269847: train_loss -0.8528 
2026-02-08 17:28:31.270223: val_loss -0.8382 
2026-02-08 17:28:31.270265: Pseudo dice [np.float32(0.9143)] 
2026-02-08 17:28:31.270342: Epoch time: 68.84 s 
2026-02-08 17:28:31.959997:  
2026-02-08 17:28:31.960119: Epoch 77 
2026-02-08 17:28:31.960215: Current learning rate: 0.0093 
2026-02-08 17:29:42.422200: train_loss -0.7899 
2026-02-08 17:29:42.422652: val_loss -0.8226 
2026-02-08 17:29:42.422728: Pseudo dice [np.float32(0.9116)] 
2026-02-08 17:29:42.422792: Epoch time: 70.46 s 
2026-02-08 17:29:43.115652:  
2026-02-08 17:29:43.116000: Epoch 78 
2026-02-08 17:29:43.116104: Current learning rate: 0.0093 
2026-02-08 17:30:52.938969: train_loss -0.862 
2026-02-08 17:30:52.939420: val_loss -0.8282 
2026-02-08 17:30:52.939466: Pseudo dice [np.float32(0.9122)] 
2026-02-08 17:30:52.939528: Epoch time: 69.82 s 
2026-02-08 17:30:53.621557:  
2026-02-08 17:30:53.621777: Epoch 79 
2026-02-08 17:30:53.621880: Current learning rate: 0.00929 
2026-02-08 17:31:59.153414: train_loss -0.8939 
2026-02-08 17:31:59.153878: val_loss -0.8739 
2026-02-08 17:31:59.153922: Pseudo dice [np.float32(0.9255)] 
2026-02-08 17:31:59.153983: Epoch time: 65.53 s 
2026-02-08 17:31:59.837317:  
2026-02-08 17:31:59.837731: Epoch 80 
2026-02-08 17:31:59.837834: Current learning rate: 0.00928 
2026-02-08 17:33:09.782707: train_loss -0.8362 
2026-02-08 17:33:09.783128: val_loss -0.7568 
2026-02-08 17:33:09.783172: Pseudo dice [np.float32(0.8496)] 
2026-02-08 17:33:09.783550: Epoch time: 69.95 s 
2026-02-08 17:33:10.476898:  
2026-02-08 17:33:10.477184: Epoch 81 
2026-02-08 17:33:10.477359: Current learning rate: 0.00927 
2026-02-08 17:34:20.223731: train_loss -0.8709 
2026-02-08 17:34:20.224175: val_loss -0.805 
2026-02-08 17:34:20.224220: Pseudo dice [np.float32(0.8918)] 
2026-02-08 17:34:20.224282: Epoch time: 69.75 s 
2026-02-08 17:34:21.609057:  
2026-02-08 17:34:21.609409: Epoch 82 
2026-02-08 17:34:21.609588: Current learning rate: 0.00926 
2026-02-08 17:35:27.839531: train_loss -0.7992 
2026-02-08 17:35:27.839887: val_loss -0.8438 
2026-02-08 17:35:27.839978: Pseudo dice [np.float32(0.9196)] 
2026-02-08 17:35:27.840045: Epoch time: 66.23 s 
2026-02-08 17:35:28.544767:  
2026-02-08 17:35:28.545149: Epoch 83 
2026-02-08 17:35:28.545300: Current learning rate: 0.00925 
2026-02-08 17:36:38.376246: train_loss -0.8401 
2026-02-08 17:36:38.376722: val_loss -0.8712 
2026-02-08 17:36:38.376765: Pseudo dice [np.float32(0.9315)] 
2026-02-08 17:36:38.376827: Epoch time: 69.83 s 
2026-02-08 17:36:39.055674:  
2026-02-08 17:36:39.056208: Epoch 84 
2026-02-08 17:36:39.056329: Current learning rate: 0.00924 
2026-02-08 17:37:50.647933: train_loss -0.8483 
2026-02-08 17:37:50.648353: val_loss -0.7876 
2026-02-08 17:37:50.648401: Pseudo dice [np.float32(0.8858)] 
2026-02-08 17:37:50.648470: Epoch time: 71.59 s 
2026-02-08 17:37:51.339364:  
2026-02-08 17:37:51.339557: Epoch 85 
2026-02-08 17:37:51.339654: Current learning rate: 0.00923 
2026-02-08 17:38:59.016666: train_loss -0.8187 
2026-02-08 17:38:59.017135: val_loss -0.9062 
2026-02-08 17:38:59.017186: Pseudo dice [np.float32(0.9556)] 
2026-02-08 17:38:59.017254: Epoch time: 67.68 s 
2026-02-08 17:38:59.699071:  
2026-02-08 17:38:59.699342: Epoch 86 
2026-02-08 17:38:59.699442: Current learning rate: 0.00922 
2026-02-08 17:40:08.692975: train_loss -0.87 
2026-02-08 17:40:08.693362: val_loss -0.9018 
2026-02-08 17:40:08.693407: Pseudo dice [np.float32(0.9523)] 
2026-02-08 17:40:08.693469: Epoch time: 68.99 s 
2026-02-08 17:40:09.389423:  
2026-02-08 17:40:09.389687: Epoch 87 
2026-02-08 17:40:09.389788: Current learning rate: 0.00921 
2026-02-08 17:41:18.058247: train_loss -0.8633 
2026-02-08 17:41:18.058622: val_loss -0.8546 
2026-02-08 17:41:18.058666: Pseudo dice [np.float32(0.9248)] 
2026-02-08 17:41:18.058716: Epoch time: 68.67 s 
2026-02-08 17:41:18.748475:  
2026-02-08 17:41:18.748729: Epoch 88 
2026-02-08 17:41:18.748831: Current learning rate: 0.0092 
2026-02-08 17:42:27.317142: train_loss -0.8652 
2026-02-08 17:42:27.317669: val_loss -0.9141 
2026-02-08 17:42:27.317718: Pseudo dice [np.float32(0.9574)] 
2026-02-08 17:42:27.317797: Epoch time: 68.57 s 
2026-02-08 17:42:27.317840: Yayy! New best EMA pseudo Dice: 0.9203000068664551 
2026-02-08 17:42:28.396059:  
2026-02-08 17:42:28.396367: Epoch 89 
2026-02-08 17:42:28.396467: Current learning rate: 0.0092 
2026-02-08 17:43:40.944828: train_loss -0.8797 
2026-02-08 17:43:40.945206: val_loss -0.8838 
2026-02-08 17:43:40.945254: Pseudo dice [np.float32(0.9381)] 
2026-02-08 17:43:40.945321: Epoch time: 72.55 s 
2026-02-08 17:43:40.945359: Yayy! New best EMA pseudo Dice: 0.921999990940094 
2026-02-08 17:43:42.001294:  
2026-02-08 17:43:42.001627: Epoch 90 
2026-02-08 17:43:42.001724: Current learning rate: 0.00919 
2026-02-08 17:44:53.076221: train_loss -0.8605 
2026-02-08 17:44:53.076663: val_loss -0.8324 
2026-02-08 17:44:53.076710: Pseudo dice [np.float32(0.9056)] 
2026-02-08 17:44:53.076765: Epoch time: 71.08 s 
2026-02-08 17:44:53.766768:  
2026-02-08 17:44:53.767163: Epoch 91 
2026-02-08 17:44:53.767262: Current learning rate: 0.00918 
2026-02-08 17:46:01.349109: train_loss -0.8647 
2026-02-08 17:46:01.349494: val_loss -0.8383 
2026-02-08 17:46:01.349536: Pseudo dice [np.float32(0.911)] 
2026-02-08 17:46:01.349588: Epoch time: 67.58 s 
2026-02-08 17:46:02.011344:  
2026-02-08 17:46:02.011637: Epoch 92 
2026-02-08 17:46:02.011738: Current learning rate: 0.00917 
2026-02-08 17:47:13.371045: train_loss -0.8279 
2026-02-08 17:47:13.371393: val_loss -0.8782 
2026-02-08 17:47:13.371438: Pseudo dice [np.float32(0.9416)] 
2026-02-08 17:47:13.371490: Epoch time: 71.36 s 
2026-02-08 17:47:14.030396:  
2026-02-08 17:47:14.030655: Epoch 93 
2026-02-08 17:47:14.030758: Current learning rate: 0.00916 
2026-02-08 17:48:23.814426: train_loss -0.8775 
2026-02-08 17:48:23.814757: val_loss -0.8609 
2026-02-08 17:48:23.814830: Pseudo dice [np.float32(0.9229)] 
2026-02-08 17:48:23.814884: Epoch time: 69.78 s 
2026-02-08 17:48:24.477518:  
2026-02-08 17:48:24.477858: Epoch 94 
2026-02-08 17:48:24.477959: Current learning rate: 0.00915 
2026-02-08 17:49:33.629760: train_loss -0.8465 
2026-02-08 17:49:33.630157: val_loss -0.9045 
2026-02-08 17:49:33.630201: Pseudo dice [np.float32(0.9511)] 
2026-02-08 17:49:33.630254: Epoch time: 69.15 s 
2026-02-08 17:49:33.630303: Yayy! New best EMA pseudo Dice: 0.9247000217437744 
2026-02-08 17:49:34.740981:  
2026-02-08 17:49:34.741179: Epoch 95 
2026-02-08 17:49:34.741283: Current learning rate: 0.00914 
2026-02-08 17:50:44.251476: train_loss -0.8799 
2026-02-08 17:50:44.251853: val_loss -0.9185 
2026-02-08 17:50:44.251894: Pseudo dice [np.float32(0.9635)] 
2026-02-08 17:50:44.251950: Epoch time: 69.51 s 
2026-02-08 17:50:44.251986: Yayy! New best EMA pseudo Dice: 0.928600013256073 
2026-02-08 17:50:46.143373:  
2026-02-08 17:50:46.143743: Epoch 96 
2026-02-08 17:50:46.143861: Current learning rate: 0.00913 
2026-02-08 17:51:53.416240: train_loss -0.8876 
2026-02-08 17:51:53.416704: val_loss -0.8781 
2026-02-08 17:51:53.416755: Pseudo dice [np.float32(0.9245)] 
2026-02-08 17:51:53.416815: Epoch time: 67.27 s 
2026-02-08 17:51:54.072302:  
2026-02-08 17:51:54.072622: Epoch 97 
2026-02-08 17:51:54.072765: Current learning rate: 0.00912 
2026-02-08 17:53:02.592479: train_loss -0.8751 
2026-02-08 17:53:02.592868: val_loss -0.8773 
2026-02-08 17:53:02.592955: Pseudo dice [np.float32(0.9389)] 
2026-02-08 17:53:02.593018: Epoch time: 68.52 s 
2026-02-08 17:53:02.593058: Yayy! New best EMA pseudo Dice: 0.9293000102043152 
2026-02-08 17:53:03.695390:  
2026-02-08 17:53:03.695615: Epoch 98 
2026-02-08 17:53:03.695740: Current learning rate: 0.00911 
2026-02-08 17:54:13.460070: train_loss -0.8373 
2026-02-08 17:54:13.460622: val_loss -0.7708 
2026-02-08 17:54:13.460668: Pseudo dice [np.float32(0.8789)] 
2026-02-08 17:54:13.460730: Epoch time: 69.77 s 
2026-02-08 17:54:14.136128:  
2026-02-08 17:54:14.136387: Epoch 99 
2026-02-08 17:54:14.136485: Current learning rate: 0.0091 
2026-02-08 17:55:21.691364: train_loss -0.8241 
2026-02-08 17:55:21.691814: val_loss -0.8143 
2026-02-08 17:55:21.691860: Pseudo dice [np.float32(0.9108)] 
2026-02-08 17:55:21.691920: Epoch time: 67.56 s 
2026-02-08 17:55:22.749342:  
2026-02-08 17:55:22.749639: Epoch 100 
2026-02-08 17:55:22.749738: Current learning rate: 0.0091 
2026-02-08 17:56:33.031600: train_loss -0.8371 
2026-02-08 17:56:33.032012: val_loss -0.7851 
2026-02-08 17:56:33.032090: Pseudo dice [np.float32(0.8766)] 
2026-02-08 17:56:33.032154: Epoch time: 70.28 s 
2026-02-08 17:56:33.739507:  
2026-02-08 17:56:33.739703: Epoch 101 
2026-02-08 17:56:33.739804: Current learning rate: 0.00909 
2026-02-08 17:57:45.122598: train_loss -0.8427 
2026-02-08 17:57:45.122940: val_loss -0.8469 
2026-02-08 17:57:45.122984: Pseudo dice [np.float32(0.929)] 
2026-02-08 17:57:45.123034: Epoch time: 71.38 s 
2026-02-08 17:57:45.796890:  
2026-02-08 17:57:45.797046: Epoch 102 
2026-02-08 17:57:45.797146: Current learning rate: 0.00908 
2026-02-08 17:58:51.815000: train_loss -0.8453 
2026-02-08 17:58:51.815386: val_loss -0.8402 
2026-02-08 17:58:51.815437: Pseudo dice [np.float32(0.92)] 
2026-02-08 17:58:51.815492: Epoch time: 66.02 s 
2026-02-08 17:58:52.478784:  
2026-02-08 17:58:52.479033: Epoch 103 
2026-02-08 17:58:52.479131: Current learning rate: 0.00907 
2026-02-08 18:00:03.640137: train_loss -0.8489 
2026-02-08 18:00:03.640492: val_loss -0.8244 
2026-02-08 18:00:03.640573: Pseudo dice [np.float32(0.876)] 
2026-02-08 18:00:03.640630: Epoch time: 71.16 s 
2026-02-08 18:00:04.304591:  
2026-02-08 18:00:04.304741: Epoch 104 
2026-02-08 18:00:04.304835: Current learning rate: 0.00906 
2026-02-08 18:01:13.353066: train_loss -0.8625 
2026-02-08 18:01:13.353312: val_loss -0.7149 
2026-02-08 18:01:13.353357: Pseudo dice [np.float32(0.8294)] 
2026-02-08 18:01:13.353593: Epoch time: 69.05 s 
2026-02-08 18:01:14.045455:  
2026-02-08 18:01:14.045666: Epoch 105 
2026-02-08 18:01:14.045766: Current learning rate: 0.00905 
2026-02-08 18:02:22.421046: train_loss -0.8451 
2026-02-08 18:02:22.421459: val_loss -0.8906 
2026-02-08 18:02:22.421505: Pseudo dice [np.float32(0.9468)] 
2026-02-08 18:02:22.421558: Epoch time: 68.38 s 
2026-02-08 18:02:23.105121:  
2026-02-08 18:02:23.105324: Epoch 106 
2026-02-08 18:02:23.105424: Current learning rate: 0.00904 
2026-02-08 18:03:33.491361: train_loss -0.8386 
2026-02-08 18:03:33.491836: val_loss -0.8514 
2026-02-08 18:03:33.491910: Pseudo dice [np.float32(0.9229)] 
2026-02-08 18:03:33.491993: Epoch time: 70.39 s 
2026-02-08 18:03:34.174612:  
2026-02-08 18:03:34.174795: Epoch 107 
2026-02-08 18:03:34.174894: Current learning rate: 0.00903 
2026-02-08 18:04:44.165656: train_loss -0.849 
2026-02-08 18:04:44.166076: val_loss -0.8446 
2026-02-08 18:04:44.166124: Pseudo dice [np.float32(0.904)] 
2026-02-08 18:04:44.166183: Epoch time: 69.99 s 
2026-02-08 18:04:44.843783:  
2026-02-08 18:04:44.843979: Epoch 108 
2026-02-08 18:04:44.844082: Current learning rate: 0.00902 
2026-02-08 18:05:53.245559: train_loss -0.8667 
2026-02-08 18:05:53.245824: val_loss -0.8764 
2026-02-08 18:05:53.245967: Pseudo dice [np.float32(0.9379)] 
2026-02-08 18:05:53.246026: Epoch time: 68.4 s 
2026-02-08 18:05:53.925388:  
2026-02-08 18:05:53.925661: Epoch 109 
2026-02-08 18:05:53.925761: Current learning rate: 0.00901 
2026-02-08 18:07:05.169710: train_loss -0.8584 
2026-02-08 18:07:05.170200: val_loss -0.8515 
2026-02-08 18:07:05.170243: Pseudo dice [np.float32(0.933)] 
2026-02-08 18:07:05.170315: Epoch time: 71.25 s 
2026-02-08 18:07:05.854253:  
2026-02-08 18:07:05.854619: Epoch 110 
2026-02-08 18:07:05.854764: Current learning rate: 0.009 
2026-02-08 18:08:16.354931: train_loss -0.8608 
2026-02-08 18:08:16.355250: val_loss -0.8524 
2026-02-08 18:08:16.355354: Pseudo dice [np.float32(0.904)] 
2026-02-08 18:08:16.355411: Epoch time: 70.5 s 
2026-02-08 18:08:17.764482:  
2026-02-08 18:08:17.764693: Epoch 111 
2026-02-08 18:08:17.764805: Current learning rate: 0.009 
2026-02-08 18:09:24.015168: train_loss -0.8516 
2026-02-08 18:09:24.015614: val_loss -0.8192 
2026-02-08 18:09:24.015665: Pseudo dice [np.float32(0.9072)] 
2026-02-08 18:09:24.015729: Epoch time: 66.25 s 
2026-02-08 18:09:24.695912:  
2026-02-08 18:09:24.696203: Epoch 112 
2026-02-08 18:09:24.696316: Current learning rate: 0.00899 
2026-02-08 18:10:33.253845: train_loss -0.8578 
2026-02-08 18:10:33.254278: val_loss -0.8782 
2026-02-08 18:10:33.254436: Pseudo dice [np.float32(0.9122)] 
2026-02-08 18:10:33.254533: Epoch time: 68.56 s 
2026-02-08 18:10:33.935694:  
2026-02-08 18:10:33.935897: Epoch 113 
2026-02-08 18:10:33.935995: Current learning rate: 0.00898 
2026-02-08 18:11:42.196173: train_loss -0.8743 
2026-02-08 18:11:42.196597: val_loss -0.8727 
2026-02-08 18:11:42.196643: Pseudo dice [np.float32(0.9287)] 
2026-02-08 18:11:42.196701: Epoch time: 68.26 s 
2026-02-08 18:11:42.880116:  
2026-02-08 18:11:42.880327: Epoch 114 
2026-02-08 18:11:42.880428: Current learning rate: 0.00897 
2026-02-08 18:12:52.787296: train_loss -0.8562 
2026-02-08 18:12:52.787618: val_loss -0.8192 
2026-02-08 18:12:52.787661: Pseudo dice [np.float32(0.9084)] 
2026-02-08 18:12:52.787711: Epoch time: 69.91 s 
2026-02-08 18:12:53.460237:  
2026-02-08 18:12:53.460533: Epoch 115 
2026-02-08 18:12:53.460633: Current learning rate: 0.00896 
2026-02-08 18:14:02.072216: train_loss -0.8843 
2026-02-08 18:14:02.072649: val_loss -0.8419 
2026-02-08 18:14:02.072695: Pseudo dice [np.float32(0.9205)] 
2026-02-08 18:14:02.072753: Epoch time: 68.61 s 
2026-02-08 18:14:02.746768:  
2026-02-08 18:14:02.747146: Epoch 116 
2026-02-08 18:14:02.747245: Current learning rate: 0.00895 
2026-02-08 18:15:08.338596: train_loss -0.8426 
2026-02-08 18:15:08.338977: val_loss -0.8394 
2026-02-08 18:15:08.339059: Pseudo dice [np.float32(0.9118)] 
2026-02-08 18:15:08.339141: Epoch time: 65.59 s 
2026-02-08 18:15:09.015085:  
2026-02-08 18:15:09.015329: Epoch 117 
2026-02-08 18:15:09.015424: Current learning rate: 0.00894 
2026-02-08 18:16:18.488228: train_loss -0.8375 
2026-02-08 18:16:18.488568: val_loss -0.8854 
2026-02-08 18:16:18.488720: Pseudo dice [np.float32(0.934)] 
2026-02-08 18:16:18.488775: Epoch time: 69.47 s 
2026-02-08 18:16:19.176048:  
2026-02-08 18:16:19.176418: Epoch 118 
2026-02-08 18:16:19.176517: Current learning rate: 0.00893 
2026-02-08 18:17:25.782410: train_loss -0.8617 
2026-02-08 18:17:25.782764: val_loss -0.8609 
2026-02-08 18:17:25.782851: Pseudo dice [np.float32(0.9354)] 
2026-02-08 18:17:25.782902: Epoch time: 66.61 s 
2026-02-08 18:17:26.474014:  
2026-02-08 18:17:26.474385: Epoch 119 
2026-02-08 18:17:26.474480: Current learning rate: 0.00892 
2026-02-08 18:18:34.863461: train_loss -0.8811 
2026-02-08 18:18:34.863713: val_loss -0.8071 
2026-02-08 18:18:34.863780: Pseudo dice [np.float32(0.8713)] 
2026-02-08 18:18:34.863836: Epoch time: 68.39 s 
2026-02-08 18:18:35.565971:  
2026-02-08 18:18:35.566216: Epoch 120 
2026-02-08 18:18:35.566329: Current learning rate: 0.00891 
2026-02-08 18:19:44.989223: train_loss -0.8367 
2026-02-08 18:19:44.989652: val_loss -0.8369 
2026-02-08 18:19:44.989696: Pseudo dice [np.float32(0.9154)] 
2026-02-08 18:19:44.989746: Epoch time: 69.42 s 
2026-02-08 18:19:45.677218:  
2026-02-08 18:19:45.677577: Epoch 121 
2026-02-08 18:19:45.677675: Current learning rate: 0.0089 
2026-02-08 18:20:54.028483: train_loss -0.8375 
2026-02-08 18:20:54.028867: val_loss -0.805 
2026-02-08 18:20:54.028932: Pseudo dice [np.float32(0.8848)] 
2026-02-08 18:20:54.029019: Epoch time: 68.35 s 
2026-02-08 18:20:54.710234:  
2026-02-08 18:20:54.710435: Epoch 122 
2026-02-08 18:20:54.710536: Current learning rate: 0.00889 
2026-02-08 18:22:04.441474: train_loss -0.8591 
2026-02-08 18:22:04.441929: val_loss -0.8613 
2026-02-08 18:22:04.441972: Pseudo dice [np.float32(0.9231)] 
2026-02-08 18:22:04.442027: Epoch time: 69.73 s 
2026-02-08 18:22:05.130371:  
2026-02-08 18:22:05.130763: Epoch 123 
2026-02-08 18:22:05.130865: Current learning rate: 0.00889 
2026-02-08 18:23:14.892699: train_loss -0.8728 
2026-02-08 18:23:14.893081: val_loss -0.8896 
2026-02-08 18:23:14.893123: Pseudo dice [np.float32(0.9491)] 
2026-02-08 18:23:14.893174: Epoch time: 69.76 s 
2026-02-08 18:23:15.573418:  
2026-02-08 18:23:15.573549: Epoch 124 
2026-02-08 18:23:15.573646: Current learning rate: 0.00888 
2026-02-08 18:24:24.113401: train_loss -0.8289 
2026-02-08 18:24:24.113702: val_loss -0.7839 
2026-02-08 18:24:24.113747: Pseudo dice [np.float32(0.8784)] 
2026-02-08 18:24:24.113800: Epoch time: 68.54 s 
2026-02-08 18:24:24.811779:  
2026-02-08 18:24:24.812054: Epoch 125 
2026-02-08 18:24:24.812233: Current learning rate: 0.00887 
2026-02-08 18:25:36.332661: train_loss -0.8516 
2026-02-08 18:25:36.332996: val_loss -0.8939 
2026-02-08 18:25:36.333094: Pseudo dice [np.float32(0.9469)] 
2026-02-08 18:25:36.333218: Epoch time: 71.52 s 
2026-02-08 18:25:36.993231:  
2026-02-08 18:25:36.993704: Epoch 126 
2026-02-08 18:25:36.993806: Current learning rate: 0.00886 
2026-02-08 18:26:46.161589: train_loss -0.866 
2026-02-08 18:26:46.161962: val_loss -0.8617 
2026-02-08 18:26:46.162048: Pseudo dice [np.float32(0.9172)] 
2026-02-08 18:26:46.162145: Epoch time: 69.17 s 
2026-02-08 18:26:46.836762:  
2026-02-08 18:26:46.837036: Epoch 127 
2026-02-08 18:26:46.837137: Current learning rate: 0.00885 
2026-02-08 18:27:53.964235: train_loss -0.8339 
2026-02-08 18:27:53.964664: val_loss -0.8599 
2026-02-08 18:27:53.964708: Pseudo dice [np.float32(0.9257)] 
2026-02-08 18:27:53.964770: Epoch time: 67.13 s 
2026-02-08 18:27:54.648526:  
2026-02-08 18:27:54.648804: Epoch 128 
2026-02-08 18:27:54.648905: Current learning rate: 0.00884 
2026-02-08 18:29:03.574854: train_loss -0.8697 
2026-02-08 18:29:03.575218: val_loss -0.9158 
2026-02-08 18:29:03.575304: Pseudo dice [np.float32(0.9541)] 
2026-02-08 18:29:03.575357: Epoch time: 68.93 s 
2026-02-08 18:29:04.264796:  
2026-02-08 18:29:04.265131: Epoch 129 
2026-02-08 18:29:04.265289: Current learning rate: 0.00883 
2026-02-08 18:30:11.662250: train_loss -0.8854 
2026-02-08 18:30:11.662672: val_loss -0.8481 
2026-02-08 18:30:11.662715: Pseudo dice [np.float32(0.9245)] 
2026-02-08 18:30:11.663107: Epoch time: 67.4 s 
2026-02-08 18:30:12.347362:  
2026-02-08 18:30:12.347653: Epoch 130 
2026-02-08 18:30:12.347757: Current learning rate: 0.00882 
2026-02-08 18:31:22.311952: train_loss -0.8853 
2026-02-08 18:31:22.312406: val_loss -0.8422 
2026-02-08 18:31:22.312450: Pseudo dice [np.float32(0.9082)] 
2026-02-08 18:31:22.312502: Epoch time: 69.97 s 
2026-02-08 18:31:22.990763:  
2026-02-08 18:31:22.990975: Epoch 131 
2026-02-08 18:31:22.991073: Current learning rate: 0.00881 
2026-02-08 18:32:33.296930: train_loss -0.8378 
2026-02-08 18:32:33.297433: val_loss -0.8849 
2026-02-08 18:32:33.297480: Pseudo dice [np.float32(0.9431)] 
2026-02-08 18:32:33.297540: Epoch time: 70.31 s 
2026-02-08 18:32:34.003024:  
2026-02-08 18:32:34.003283: Epoch 132 
2026-02-08 18:32:34.003383: Current learning rate: 0.0088 
2026-02-08 18:33:43.664953: train_loss -0.8556 
2026-02-08 18:33:43.665416: val_loss -0.9031 
2026-02-08 18:33:43.665460: Pseudo dice [np.float32(0.9508)] 
2026-02-08 18:33:43.665521: Epoch time: 69.66 s 
2026-02-08 18:33:44.346707:  
2026-02-08 18:33:44.346960: Epoch 133 
2026-02-08 18:33:44.347051: Current learning rate: 0.00879 
2026-02-08 18:34:56.725999: train_loss -0.8624 
2026-02-08 18:34:56.726362: val_loss -0.8824 
2026-02-08 18:34:56.726408: Pseudo dice [np.float32(0.9392)] 
2026-02-08 18:34:56.726466: Epoch time: 72.38 s 
2026-02-08 18:34:57.406714:  
2026-02-08 18:34:57.406919: Epoch 134 
2026-02-08 18:34:57.407068: Current learning rate: 0.00879 
2026-02-08 18:36:09.096941: train_loss -0.875 
2026-02-08 18:36:09.097354: val_loss -0.8319 
2026-02-08 18:36:09.097399: Pseudo dice [np.float32(0.9199)] 
2026-02-08 18:36:09.097458: Epoch time: 71.69 s 
2026-02-08 18:36:09.795219:  
2026-02-08 18:36:09.795551: Epoch 135 
2026-02-08 18:36:09.795651: Current learning rate: 0.00878 
2026-02-08 18:37:18.287946: train_loss -0.8656 
2026-02-08 18:37:18.288434: val_loss -0.8776 
2026-02-08 18:37:18.288479: Pseudo dice [np.float32(0.9351)] 
2026-02-08 18:37:18.288541: Epoch time: 68.49 s 
2026-02-08 18:37:18.982006:  
2026-02-08 18:37:18.982323: Epoch 136 
2026-02-08 18:37:18.982481: Current learning rate: 0.00877 
2026-02-08 18:38:26.129396: train_loss -0.8957 
2026-02-08 18:38:26.129895: val_loss -0.8356 
2026-02-08 18:38:26.129937: Pseudo dice [np.float32(0.924)] 
2026-02-08 18:38:26.130011: Epoch time: 67.15 s 
2026-02-08 18:38:26.829760:  
2026-02-08 18:38:26.830123: Epoch 137 
2026-02-08 18:38:26.830222: Current learning rate: 0.00876 
2026-02-08 18:39:38.897776: train_loss -0.8662 
2026-02-08 18:39:38.898231: val_loss -0.8905 
2026-02-08 18:39:38.898289: Pseudo dice [np.float32(0.9452)] 
2026-02-08 18:39:38.898351: Epoch time: 72.07 s 
2026-02-08 18:39:39.593810:  
2026-02-08 18:39:39.594104: Epoch 138 
2026-02-08 18:39:39.594204: Current learning rate: 0.00875 
2026-02-08 18:40:52.646466: train_loss -0.8129 
2026-02-08 18:40:52.646921: val_loss -0.851 
2026-02-08 18:40:52.646965: Pseudo dice [np.float32(0.9228)] 
2026-02-08 18:40:52.647030: Epoch time: 73.05 s 
2026-02-08 18:40:54.039836:  
2026-02-08 18:40:54.040166: Epoch 139 
2026-02-08 18:40:54.040291: Current learning rate: 0.00874 
2026-02-08 18:42:03.691456: train_loss -0.8405 
2026-02-08 18:42:03.691836: val_loss -0.8747 
2026-02-08 18:42:03.691923: Pseudo dice [np.float32(0.9398)] 
2026-02-08 18:42:03.692074: Epoch time: 69.65 s 
2026-02-08 18:42:04.362909:  
2026-02-08 18:42:04.363210: Epoch 140 
2026-02-08 18:42:04.363353: Current learning rate: 0.00873 
2026-02-08 18:43:14.642690: train_loss -0.855 
2026-02-08 18:43:14.643117: val_loss -0.8891 
2026-02-08 18:43:14.643165: Pseudo dice [np.float32(0.9456)] 
2026-02-08 18:43:14.643226: Epoch time: 70.28 s 
2026-02-08 18:43:14.643264: Yayy! New best EMA pseudo Dice: 0.9305999875068665 
2026-02-08 18:43:15.769644:  
2026-02-08 18:43:15.769847: Epoch 141 
2026-02-08 18:43:15.769945: Current learning rate: 0.00872 
2026-02-08 18:44:25.795729: train_loss -0.837 
2026-02-08 18:44:25.796200: val_loss -0.9133 
2026-02-08 18:44:25.796247: Pseudo dice [np.float32(0.9545)] 
2026-02-08 18:44:25.796317: Epoch time: 70.03 s 
2026-02-08 18:44:25.796355: Yayy! New best EMA pseudo Dice: 0.9330000281333923 
2026-02-08 18:44:26.882566:  
2026-02-08 18:44:26.882915: Epoch 142 
2026-02-08 18:44:26.883014: Current learning rate: 0.00871 
2026-02-08 18:45:35.044219: train_loss -0.8748 
2026-02-08 18:45:35.044721: val_loss -0.8787 
2026-02-08 18:45:35.044769: Pseudo dice [np.float32(0.9391)] 
2026-02-08 18:45:35.044832: Epoch time: 68.16 s 
2026-02-08 18:45:35.044877: Yayy! New best EMA pseudo Dice: 0.9336000084877014 
2026-02-08 18:45:36.127466:  
2026-02-08 18:45:36.127717: Epoch 143 
2026-02-08 18:45:36.127824: Current learning rate: 0.0087 
2026-02-08 18:46:45.864278: train_loss -0.8629 
2026-02-08 18:46:45.864635: val_loss -0.8913 
2026-02-08 18:46:45.864684: Pseudo dice [np.float32(0.9438)] 
2026-02-08 18:46:45.864744: Epoch time: 69.74 s 
2026-02-08 18:46:45.864780: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2026-02-08 18:46:46.976879:  
2026-02-08 18:46:46.977177: Epoch 144 
2026-02-08 18:46:46.977286: Current learning rate: 0.00869 
2026-02-08 18:47:58.718112: train_loss -0.8939 
2026-02-08 18:47:58.718521: val_loss -0.8342 
2026-02-08 18:47:58.718606: Pseudo dice [np.float32(0.9025)] 
2026-02-08 18:47:58.718669: Epoch time: 71.74 s 
2026-02-08 18:47:59.413311:  
2026-02-08 18:47:59.413557: Epoch 145 
2026-02-08 18:47:59.413653: Current learning rate: 0.00868 
2026-02-08 18:49:07.130287: train_loss -0.8828 
2026-02-08 18:49:07.130698: val_loss -0.8419 
2026-02-08 18:49:07.130747: Pseudo dice [np.float32(0.9168)] 
2026-02-08 18:49:07.130803: Epoch time: 67.72 s 
2026-02-08 18:49:07.821753:  
2026-02-08 18:49:07.822012: Epoch 146 
2026-02-08 18:49:07.822134: Current learning rate: 0.00868 
2026-02-08 18:50:18.291284: train_loss -0.8656 
2026-02-08 18:50:18.291722: val_loss -0.8854 
2026-02-08 18:50:18.291764: Pseudo dice [np.float32(0.9389)] 
2026-02-08 18:50:18.291822: Epoch time: 70.47 s 
2026-02-08 18:50:19.001135:  
2026-02-08 18:50:19.001377: Epoch 147 
2026-02-08 18:50:19.001475: Current learning rate: 0.00867 
2026-02-08 18:51:27.649439: train_loss -0.8738 
2026-02-08 18:51:27.649915: val_loss -0.8723 
2026-02-08 18:51:27.649967: Pseudo dice [np.float32(0.9248)] 
2026-02-08 18:51:27.650025: Epoch time: 68.65 s 
2026-02-08 18:51:28.368395:  
2026-02-08 18:51:28.368781: Epoch 148 
2026-02-08 18:51:28.368898: Current learning rate: 0.00866 
2026-02-08 18:52:37.440453: train_loss -0.9 
2026-02-08 18:52:37.440929: val_loss -0.8255 
2026-02-08 18:52:37.440974: Pseudo dice [np.float32(0.9162)] 
2026-02-08 18:52:37.441032: Epoch time: 69.07 s 
2026-02-08 18:52:38.134331:  
2026-02-08 18:52:38.134684: Epoch 149 
2026-02-08 18:52:38.134811: Current learning rate: 0.00865 
2026-02-08 18:53:48.180912: train_loss -0.8921 
2026-02-08 18:53:48.181408: val_loss -0.9053 
2026-02-08 18:53:48.181452: Pseudo dice [np.float32(0.9499)] 
2026-02-08 18:53:48.181508: Epoch time: 70.05 s 
2026-02-08 18:53:49.279059:  
2026-02-08 18:53:49.279214: Epoch 150 
2026-02-08 18:53:49.279319: Current learning rate: 0.00864 
2026-02-08 18:55:00.694652: train_loss -0.8489 
2026-02-08 18:55:00.695043: val_loss -0.8865 
2026-02-08 18:55:00.695090: Pseudo dice [np.float32(0.9415)] 
2026-02-08 18:55:00.695149: Epoch time: 71.42 s 
2026-02-08 18:55:01.396862:  
2026-02-08 18:55:01.397058: Epoch 151 
2026-02-08 18:55:01.397158: Current learning rate: 0.00863 
2026-02-08 18:56:08.896194: train_loss -0.8482 
2026-02-08 18:56:08.896625: val_loss -0.8112 
2026-02-08 18:56:08.896679: Pseudo dice [np.float32(0.899)] 
2026-02-08 18:56:08.896739: Epoch time: 67.5 s 
2026-02-08 18:56:09.595830:  
2026-02-08 18:56:09.596068: Epoch 152 
2026-02-08 18:56:09.596170: Current learning rate: 0.00862 
2026-02-08 18:57:18.205092: train_loss -0.8275 
2026-02-08 18:57:18.205407: val_loss -0.863 
2026-02-08 18:57:18.205451: Pseudo dice [np.float32(0.9365)] 
2026-02-08 18:57:18.205510: Epoch time: 68.61 s 
2026-02-08 18:57:19.657947:  
2026-02-08 18:57:19.658343: Epoch 153 
2026-02-08 18:57:19.658548: Current learning rate: 0.00861 
2026-02-08 18:58:27.745283: train_loss -0.8435 
2026-02-08 18:58:27.745770: val_loss -0.8617 
2026-02-08 18:58:27.745813: Pseudo dice [np.float32(0.9154)] 
2026-02-08 18:58:27.745874: Epoch time: 68.09 s 
2026-02-08 18:58:28.428009:  
2026-02-08 18:58:28.428242: Epoch 154 
2026-02-08 18:58:28.428400: Current learning rate: 0.0086 
2026-02-08 18:59:37.341821: train_loss -0.8707 
2026-02-08 18:59:37.342305: val_loss -0.8956 
2026-02-08 18:59:37.342354: Pseudo dice [np.float32(0.9486)] 
2026-02-08 18:59:37.342415: Epoch time: 68.91 s 
2026-02-08 18:59:38.043383:  
2026-02-08 18:59:38.043610: Epoch 155 
2026-02-08 18:59:38.043710: Current learning rate: 0.00859 
2026-02-08 19:00:48.527656: train_loss -0.8464 
2026-02-08 19:00:48.528059: val_loss -0.7127 
2026-02-08 19:00:48.528101: Pseudo dice [np.float32(0.8573)] 
2026-02-08 19:00:48.528158: Epoch time: 70.49 s 
2026-02-08 19:00:49.221387:  
2026-02-08 19:00:49.221629: Epoch 156 
2026-02-08 19:00:49.221753: Current learning rate: 0.00858 
2026-02-08 19:01:56.220132: train_loss -0.8709 
2026-02-08 19:01:56.220604: val_loss -0.9169 
2026-02-08 19:01:56.220653: Pseudo dice [np.float32(0.9611)] 
2026-02-08 19:01:56.220712: Epoch time: 67.0 s 
2026-02-08 19:01:56.916462:  
2026-02-08 19:01:56.916748: Epoch 157 
2026-02-08 19:01:56.916852: Current learning rate: 0.00858 
2026-02-08 19:03:05.608140: train_loss -0.8446 
2026-02-08 19:03:05.608612: val_loss -0.8451 
2026-02-08 19:03:05.608658: Pseudo dice [np.float32(0.917)] 
2026-02-08 19:03:05.608712: Epoch time: 68.69 s 
2026-02-08 19:03:06.318773:  
2026-02-08 19:03:06.318995: Epoch 158 
2026-02-08 19:03:06.319096: Current learning rate: 0.00857 
2026-02-08 19:04:17.373711: train_loss -0.866 
2026-02-08 19:04:17.374077: val_loss -0.8771 
2026-02-08 19:04:17.374119: Pseudo dice [np.float32(0.9386)] 
2026-02-08 19:04:17.374174: Epoch time: 71.06 s 
2026-02-08 19:04:18.089164:  
2026-02-08 19:04:18.089380: Epoch 159 
2026-02-08 19:04:18.089477: Current learning rate: 0.00856 
2026-02-08 19:05:27.884018: train_loss -0.8471 
2026-02-08 19:05:27.884459: val_loss -0.8274 
2026-02-08 19:05:27.884503: Pseudo dice [np.float32(0.8924)] 
2026-02-08 19:05:27.884556: Epoch time: 69.8 s 
2026-02-08 19:05:28.574097:  
2026-02-08 19:05:28.574315: Epoch 160 
2026-02-08 19:05:28.574427: Current learning rate: 0.00855 
2026-02-08 19:06:37.809449: train_loss -0.8258 
2026-02-08 19:06:37.809836: val_loss -0.8133 
2026-02-08 19:06:37.809879: Pseudo dice [np.float32(0.8885)] 
2026-02-08 19:06:37.809932: Epoch time: 69.24 s 
2026-02-08 19:06:38.512220:  
2026-02-08 19:06:38.512641: Epoch 161 
2026-02-08 19:06:38.512784: Current learning rate: 0.00854 
2026-02-08 19:07:49.273483: train_loss -0.8272 
2026-02-08 19:07:49.273969: val_loss -0.8605 
2026-02-08 19:07:49.274047: Pseudo dice [np.float32(0.9323)] 
2026-02-08 19:07:49.274123: Epoch time: 70.76 s 
2026-02-08 19:07:50.001642:  
2026-02-08 19:07:50.001976: Epoch 162 
2026-02-08 19:07:50.002094: Current learning rate: 0.00853 
2026-02-08 19:08:57.608433: train_loss -0.8692 
2026-02-08 19:08:57.608840: val_loss -0.7929 
2026-02-08 19:08:57.608888: Pseudo dice [np.float32(0.8944)] 
2026-02-08 19:08:57.608956: Epoch time: 67.61 s 
2026-02-08 19:08:58.313658:  
2026-02-08 19:08:58.313944: Epoch 163 
2026-02-08 19:08:58.314048: Current learning rate: 0.00852 
2026-02-08 19:10:07.276053: train_loss -0.8509 
2026-02-08 19:10:07.276841: val_loss -0.8314 
2026-02-08 19:10:07.276895: Pseudo dice [np.float32(0.9097)] 
2026-02-08 19:10:07.277029: Epoch time: 68.96 s 
2026-02-08 19:10:07.990781:  
2026-02-08 19:10:07.990894: Epoch 164 
2026-02-08 19:10:07.990973: Current learning rate: 0.00851 
2026-02-08 19:11:15.588630: train_loss -0.833 
2026-02-08 19:11:15.589160: val_loss -0.8621 
2026-02-08 19:11:15.589285: Pseudo dice [np.float32(0.9209)] 
2026-02-08 19:11:15.589359: Epoch time: 67.6 s 
2026-02-08 19:11:16.281354:  
2026-02-08 19:11:16.281561: Epoch 165 
2026-02-08 19:11:16.281652: Current learning rate: 0.0085 
2026-02-08 19:12:24.858489: train_loss -0.8529 
2026-02-08 19:12:24.859058: val_loss -0.8381 
2026-02-08 19:12:24.859108: Pseudo dice [np.float32(0.9069)] 
2026-02-08 19:12:24.859196: Epoch time: 68.58 s 
2026-02-08 19:12:25.549273:  
2026-02-08 19:12:25.549379: Epoch 166 
2026-02-08 19:12:25.549466: Current learning rate: 0.00849 
2026-02-08 19:13:36.116500: train_loss -0.8746 
2026-02-08 19:13:36.116861: val_loss -0.9037 
2026-02-08 19:13:36.116980: Pseudo dice [np.float32(0.9477)] 
2026-02-08 19:13:36.117042: Epoch time: 70.57 s 
2026-02-08 19:13:37.425398:  
2026-02-08 19:13:37.425693: Epoch 167 
2026-02-08 19:13:37.425821: Current learning rate: 0.00848 
2026-02-08 19:14:45.158606: train_loss -0.8751 
2026-02-08 19:14:45.159033: val_loss -0.8642 
2026-02-08 19:14:45.159080: Pseudo dice [np.float32(0.9258)] 
2026-02-08 19:14:45.159142: Epoch time: 67.73 s 
2026-02-08 19:14:45.890646:  
2026-02-08 19:14:45.891023: Epoch 168 
2026-02-08 19:14:45.891117: Current learning rate: 0.00847 
2026-02-08 19:15:53.277338: train_loss -0.8902 
2026-02-08 19:15:53.277728: val_loss -0.8589 
2026-02-08 19:15:53.277776: Pseudo dice [np.float32(0.9275)] 
2026-02-08 19:15:53.277839: Epoch time: 67.39 s 
2026-02-08 19:15:53.981036:  
2026-02-08 19:15:53.981304: Epoch 169 
2026-02-08 19:15:53.981400: Current learning rate: 0.00847 
2026-02-08 19:17:02.329525: train_loss -0.8528 
2026-02-08 19:17:02.329992: val_loss -0.8134 
2026-02-08 19:17:02.330039: Pseudo dice [np.float32(0.9054)] 
2026-02-08 19:17:02.330102: Epoch time: 68.35 s 
2026-02-08 19:17:03.021240:  
2026-02-08 19:17:03.021516: Epoch 170 
2026-02-08 19:17:03.021649: Current learning rate: 0.00846 
2026-02-08 19:18:11.071067: train_loss -0.8938 
2026-02-08 19:18:11.071551: val_loss -0.8796 
2026-02-08 19:18:11.071599: Pseudo dice [np.float32(0.9415)] 
2026-02-08 19:18:11.071663: Epoch time: 68.05 s 
2026-02-08 19:18:11.761461:  
2026-02-08 19:18:11.761746: Epoch 171 
2026-02-08 19:18:11.761857: Current learning rate: 0.00845 
2026-02-08 19:19:21.195721: train_loss -0.8639 
2026-02-08 19:19:21.196192: val_loss -0.9003 
2026-02-08 19:19:21.196239: Pseudo dice [np.float32(0.9512)] 
2026-02-08 19:19:21.196311: Epoch time: 69.44 s 
2026-02-08 19:19:21.893451:  
2026-02-08 19:19:21.893836: Epoch 172 
2026-02-08 19:19:21.893952: Current learning rate: 0.00844 
2026-02-08 19:20:30.558180: train_loss -0.8843 
2026-02-08 19:20:30.558579: val_loss -0.8981 
2026-02-08 19:20:30.558623: Pseudo dice [np.float32(0.9493)] 
2026-02-08 19:20:30.558698: Epoch time: 68.67 s 
2026-02-08 19:20:31.264229:  
2026-02-08 19:20:31.264655: Epoch 173 
2026-02-08 19:20:31.264758: Current learning rate: 0.00843 
2026-02-08 19:21:38.370340: train_loss -0.8828 
2026-02-08 19:21:38.370744: val_loss -0.8207 
2026-02-08 19:21:38.370794: Pseudo dice [np.float32(0.9047)] 
2026-02-08 19:21:38.370843: Epoch time: 67.11 s 
2026-02-08 19:21:39.066046:  
2026-02-08 19:21:39.066422: Epoch 174 
2026-02-08 19:21:39.066512: Current learning rate: 0.00842 
2026-02-08 19:22:50.205472: train_loss -0.8388 
2026-02-08 19:22:50.205971: val_loss -0.8122 
2026-02-08 19:22:50.206060: Pseudo dice [np.float32(0.8941)] 
2026-02-08 19:22:50.206142: Epoch time: 71.14 s 
2026-02-08 19:22:50.915598:  
2026-02-08 19:22:50.915845: Epoch 175 
2026-02-08 19:22:50.915940: Current learning rate: 0.00841 
2026-02-08 19:23:57.878655: train_loss -0.8295 
2026-02-08 19:23:57.879081: val_loss -0.8915 
2026-02-08 19:23:57.879126: Pseudo dice [np.float32(0.9465)] 
2026-02-08 19:23:57.879192: Epoch time: 66.96 s 
2026-02-08 19:23:58.580690:  
2026-02-08 19:23:58.581029: Epoch 176 
2026-02-08 19:23:58.581180: Current learning rate: 0.0084 
2026-02-08 19:25:09.770017: train_loss -0.8684 
2026-02-08 19:25:09.770399: val_loss -0.8767 
2026-02-08 19:25:09.770524: Pseudo dice [np.float32(0.9334)] 
2026-02-08 19:25:09.770592: Epoch time: 71.19 s 
2026-02-08 19:25:10.471196:  
2026-02-08 19:25:10.471390: Epoch 177 
2026-02-08 19:25:10.471469: Current learning rate: 0.00839 
2026-02-08 19:26:21.724105: train_loss -0.8426 
2026-02-08 19:26:21.724539: val_loss -0.8415 
2026-02-08 19:26:21.724630: Pseudo dice [np.float32(0.9146)] 
2026-02-08 19:26:21.724699: Epoch time: 71.25 s 
2026-02-08 19:26:22.426257:  
2026-02-08 19:26:22.426635: Epoch 178 
2026-02-08 19:26:22.426733: Current learning rate: 0.00838 
2026-02-08 19:27:30.781745: train_loss -0.8995 
2026-02-08 19:27:30.782179: val_loss -0.8566 
2026-02-08 19:27:30.782257: Pseudo dice [np.float32(0.9182)] 
2026-02-08 19:27:30.782343: Epoch time: 68.36 s 
2026-02-08 19:27:31.496118:  
2026-02-08 19:27:31.496346: Epoch 179 
2026-02-08 19:27:31.496439: Current learning rate: 0.00837 
2026-02-08 19:28:39.628491: train_loss -0.8966 
2026-02-08 19:28:39.628928: val_loss -0.8813 
2026-02-08 19:28:39.629008: Pseudo dice [np.float32(0.9366)] 
2026-02-08 19:28:39.629075: Epoch time: 68.13 s 
2026-02-08 19:28:40.323227:  
2026-02-08 19:28:40.323468: Epoch 180 
2026-02-08 19:28:40.323559: Current learning rate: 0.00836 
2026-02-08 19:29:48.089583: train_loss -0.8444 
2026-02-08 19:29:48.090026: val_loss -0.8308 
2026-02-08 19:29:48.090075: Pseudo dice [np.float32(0.8936)] 
2026-02-08 19:29:48.090139: Epoch time: 67.77 s 
2026-02-08 19:29:49.371404:  
2026-02-08 19:29:49.371607: Epoch 181 
2026-02-08 19:29:49.371714: Current learning rate: 0.00836 
